{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>voted_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While it does feel like they needed a bit more...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Game is asbolutely good. The Night City is som...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This game has a JoJo reference.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheers everyone, after 8 years we finally made...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>made my penis to perfection in a call with fri...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>The game doesn't bring anything new to the tab...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>pp go smol ( ͡° ͜ʖ ͡°)\\n\\npp go big (˵ ͡☉ ͜ʖ ͡...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Great characters, nice city, thrilling storyli...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>So here is my review after all of this time.\\n...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Here's the headline: If you enjoy Far Cry, Tom...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  voted_up\n",
       "0     While it does feel like they needed a bit more...      True\n",
       "1     Game is asbolutely good. The Night City is som...      True\n",
       "2                       This game has a JoJo reference.      True\n",
       "3     Cheers everyone, after 8 years we finally made...      True\n",
       "4     made my penis to perfection in a call with fri...      True\n",
       "...                                                 ...       ...\n",
       "1995  The game doesn't bring anything new to the tab...     False\n",
       "1996  pp go smol ( ͡° ͜ʖ ͡°)\\n\\npp go big (˵ ͡☉ ͜ʖ ͡...      True\n",
       "1997  Great characters, nice city, thrilling storyli...      True\n",
       "1998  So here is my review after all of this time.\\n...      True\n",
       "1999  Here's the headline: If you enjoy Far Cry, Tom...      True\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/test_reviews.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   review    2000 non-null   object\n",
      " 1   voted_up  2000 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 17.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500,), (1500,), (500,), (500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, random_state=212)\n",
    "X_train, y_train = df_train['review'], df_train['voted_up']\n",
    "X_test, y_test = df_test['review'], df_test['voted_up']\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- frequency distribution\n",
    "- total vocab\n",
    "- word clouds\n",
    "\n",
    "comparative EDA - compare values in both classes\n",
    "\n",
    "watch topic 39 video at around 52:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "total_vocabulary = set(word for review in X_train_tokenized for word in review)\n",
    "len(total_vocabulary)\n",
    "print('There are {} unique tokens in the dataset.'.format(len(total_vocabulary)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_list = list(punctuation) + ['`', '’', '…']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(review):\n",
    "    review = re.sub(r'\\[.*?\\]', '', review) # remove markdown tags, only needed for Steam reviews\n",
    "    review = review.translate(str.maketrans('', '', ''.join(punctuation_list))) # remove all punctuation\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+') # tokenize words with only numbers and latin characters\n",
    "    return tokenizer.tokenize(review.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized = list(map(tokenize, X_train))\n",
    "X_test_tokenized = list(map(tokenize, X_test))\n",
    "len(X_train_tokenized), len(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop-Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english') + punctuation_list\n",
    "len(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stopworded = [[word for word in review if word not in stopwords_list] for review in X_train_tokenized]\n",
    "X_test_stopworded = [[word for word in review if word not in stopwords_list] for review in X_test_tokenized]\n",
    "len(X_train_stopworded), len(X_test_stopworded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "X_train_lemmatized = [list(map(lemmatizer.lemmatize, review)) for review in X_train_stopworded]\n",
    "X_test_lemmatized = [list(map(lemmatizer.lemmatize, review)) for review in X_test_stopworded]\n",
    "len(X_train_lemmatized), len(X_test_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed = [' '.join(review) for review in X_train_lemmatized]\n",
    "X_test_preprocessed = [' '.join(review) for review in X_test_lemmatized]\n",
    "X_train_split = [review.split(' ') for review in X_train_preprocessed]\n",
    "X_test_split = [review.split(' ') for review in X_test_preprocessed]\n",
    "len(X_train_preprocessed), len(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 12529), (500, 12529))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train_bow = pd.DataFrame(cv.fit_transform(X_train_preprocessed).todense(), columns=cv.get_feature_names())\n",
    "X_test_bow = pd.DataFrame(cv.transform(X_test_preprocessed).todense(), columns=cv.get_feature_names())\n",
    "X_train_bow.shape, X_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 12529), (500, 12529))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "X_train_tf = pd.DataFrame(tf.fit_transform(X_train_preprocessed).todense(), columns=tf.get_feature_names())\n",
    "X_test_tf = pd.DataFrame(tf.transform(X_test_preprocessed).todense(), columns=tf.get_feature_names())\n",
    "X_train_tf.shape, X_test_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.sklearn_api import D2VTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 100), (500, 100))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = D2VTransformer()\n",
    "scaler = MinMaxScaler((1, 2)) # scaled to prevent negative values, which do not work with Naive Bayes models\n",
    "X_train_embed = scaler.fit_transform(pd.DataFrame(vectorizer.fit_transform(X_train_split)))\n",
    "X_test_embed = scaler.transform(pd.DataFrame(vectorizer.transform(X_test_split)))\n",
    "X_train_embed.shape, X_test_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_train, y_hat_train, y_test, y_hat_test):\n",
    "    train_accuracy = accuracy_score(y_train, y_hat_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_hat_test)\n",
    "    train_precision = precision_score(y_train, y_hat_train)\n",
    "    test_precision = precision_score(y_test, y_hat_test)\n",
    "    train_recall = recall_score(y_train, y_hat_train)\n",
    "    test_recall = recall_score(y_test, y_hat_test)\n",
    "    \n",
    "    print('\\t\\tAccuracy\\tPrecision\\tRecall')\n",
    "    print(f'Training:\\t{round(train_accuracy, 2)}\\t\\t{round(train_precision, 2)}\\t\\t{round(train_recall, 2)}')\n",
    "    print(f'Testing:\\t{round(test_accuracy, 2)}\\t\\t{round(test_precision, 2)}\\t\\t{round(test_recall, 2)}')\n",
    "    \n",
    "    return {'train_accuracy':train_accuracy, 'train_precision':train_precision, 'train_recall':train_recall,\n",
    "            'test_accuracy':test_accuracy, 'test_precision':test_precision, 'test_recall':test_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.596667\n",
       "False    0.403333\n",
       "Name: voted_up, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = [True]*len(y_train)\n",
    "test_preds = [True]*len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict only \"Suggested\"\tNone\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.63\t\t0.63\t\t0.93\n",
      "Testing:\t0.63\t\t0.64\t\t0.91\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Predict only \"Suggested\"'\n",
    "data_name = 'None'\n",
    "print(f'{model_name}\\t{data_name}')\n",
    "metrics = {'model':model_name, 'data':data_name}\n",
    "metrics.update(get_metrics(y_train, train_preds, y_test, test_preds))\n",
    "model_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Logistic Regression', LogisticRegression),\n",
    "          ('Multinomial Naive Bayes', MultinomialNB),\n",
    "          ('Random Forest', RandomForestClassifier),\n",
    "          ('Support Vector Machines', SVC)]\n",
    "datasets = [('Bag of Words', X_train_bow, X_test_bow),\n",
    "             ('TF-IDF', X_train_tf, X_test_tf),\n",
    "             ('Document Embeddings', X_train_embed, X_test_embed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.98\t\t0.97\t\t1.0\n",
      "Testing:\t0.82\t\t0.84\t\t0.87\n",
      "\n",
      "Logistic Regression\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.92\t\t0.89\t\t0.98\n",
      "Testing:\t0.83\t\t0.81\t\t0.95\n",
      "\n",
      "Logistic Regression\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.63\t\t0.63\t\t0.93\n",
      "Testing:\t0.64\t\t0.65\t\t0.92\n",
      "\n",
      "Multinomial Naive Bayes\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.94\t\t0.93\t\t0.97\n",
      "Testing:\t0.8\t\t0.83\t\t0.86\n",
      "\n",
      "Multinomial Naive Bayes\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.85\t\t0.8\t\t1.0\n",
      "Testing:\t0.73\t\t0.71\t\t0.98\n",
      "\n",
      "Multinomial Naive Bayes\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.6\t\t0.61\t\t0.92\n",
      "Testing:\t0.61\t\t0.63\t\t0.91\n",
      "\n",
      "Random Forest\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t1.0\t\t1.0\n",
      "Testing:\t0.77\t\t0.81\t\t0.82\n",
      "\n",
      "Random Forest\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t1.0\t\t1.0\n",
      "Testing:\t0.77\t\t0.78\t\t0.88\n",
      "\n",
      "Random Forest\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t1.0\t\t1.0\n",
      "Testing:\t0.67\t\t0.7\t\t0.82\n",
      "\n",
      "Support Vector Machines\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.82\t\t0.78\t\t0.99\n",
      "Testing:\t0.75\t\t0.72\t\t0.97\n",
      "\n",
      "Support Vector Machines\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t0.99\t\t1.0\n",
      "Testing:\t0.83\t\t0.82\t\t0.93\n",
      "\n",
      "Support Vector Machines\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.63\t\t0.63\t\t0.93\n",
      "Testing:\t0.63\t\t0.64\t\t0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models:\n",
    "    for data_name, X_train, X_test in datasets:\n",
    "        classifier = model()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        train_preds = classifier.predict(X_train)\n",
    "        test_preds = classifier.predict(X_test)\n",
    "\n",
    "        print(f'{model_name}\\t\\t{data_name}')\n",
    "        metrics = {'model':model_name, 'data':data_name}\n",
    "        metrics.update(get_metrics(y_train, train_preds, y_test, test_preds))\n",
    "        print()\n",
    "        model_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.992239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.819718</td>\n",
       "      <td>0.932692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.920667</td>\n",
       "      <td>0.893509</td>\n",
       "      <td>0.984358</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.810440</td>\n",
       "      <td>0.945513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.862179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.996659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.997768</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.805643</td>\n",
       "      <td>0.823718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.824667</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.992179</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.724880</td>\n",
       "      <td>0.971154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.847333</td>\n",
       "      <td>0.796263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.707657</td>\n",
       "      <td>0.977564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.823718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.629239</td>\n",
       "      <td>0.932961</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predict only \"Suggested\"</td>\n",
       "      <td>None</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.610863</td>\n",
       "      <td>0.917318</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.633110</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model                 data  train_accuracy  \\\n",
       "11   Support Vector Machines               TF-IDF        0.995333   \n",
       "2        Logistic Regression               TF-IDF        0.920667   \n",
       "1        Logistic Regression         Bag of Words        0.983333   \n",
       "4    Multinomial Naive Bayes         Bag of Words        0.938000   \n",
       "8              Random Forest               TF-IDF        0.998000   \n",
       "7              Random Forest         Bag of Words        0.998000   \n",
       "10   Support Vector Machines         Bag of Words        0.824667   \n",
       "5    Multinomial Naive Bayes               TF-IDF        0.847333   \n",
       "9              Random Forest  Document Embeddings        1.000000   \n",
       "3        Logistic Regression  Document Embeddings        0.632000   \n",
       "0   Predict only \"Suggested\"                 None        0.626000   \n",
       "12   Support Vector Machines  Document Embeddings        0.626000   \n",
       "6    Multinomial Naive Bayes  Document Embeddings        0.602000   \n",
       "\n",
       "    train_precision  train_recall  test_accuracy  test_precision  test_recall  \n",
       "11         0.992239      1.000000          0.830        0.819718     0.932692  \n",
       "2          0.893509      0.984358          0.828        0.810440     0.945513  \n",
       "1          0.972826      1.000000          0.816        0.839506     0.871795  \n",
       "4          0.929336      0.969832          0.802        0.827692     0.862179  \n",
       "8          0.996659      1.000000          0.772        0.779661     0.884615  \n",
       "7          0.997768      0.998883          0.766        0.805643     0.823718  \n",
       "10         0.776224      0.992179          0.752        0.724880     0.971154  \n",
       "5          0.796263      1.000000          0.734        0.707657     0.977564  \n",
       "9          1.000000      1.000000          0.672        0.702186     0.823718  \n",
       "3          0.629239      0.932961          0.644        0.651584     0.923077  \n",
       "0          0.625753      0.928492          0.630        0.644647     0.907051  \n",
       "12         0.625753      0.928492          0.630        0.644647     0.907051  \n",
       "6          0.610863      0.917318          0.614        0.633110     0.907051  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_df = pd.DataFrame(model_metrics)\n",
    "model_metrics_df.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.845333</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.762667</td>\n",
       "      <td>0.767176</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.798072</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>0.729749</td>\n",
       "      <td>0.936966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.762496</td>\n",
       "      <td>0.844017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.795778</td>\n",
       "      <td>0.778821</td>\n",
       "      <td>0.962384</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.722820</td>\n",
       "      <td>0.915598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict only \"Suggested\"</th>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          train_accuracy  train_precision  train_recall  \\\n",
       "model                                                                     \n",
       "Logistic Regression             0.845333         0.831858      0.972439   \n",
       "Support Vector Machines         0.815333         0.798072      0.973557   \n",
       "Random Forest                   0.998667         0.998142      0.999628   \n",
       "Multinomial Naive Bayes         0.795778         0.778821      0.962384   \n",
       "Predict only \"Suggested\"        0.626000         0.625753      0.928492   \n",
       "\n",
       "                          test_accuracy  test_precision  test_recall  \n",
       "model                                                                 \n",
       "Logistic Regression            0.762667        0.767176     0.913462  \n",
       "Support Vector Machines        0.737333        0.729749     0.936966  \n",
       "Random Forest                  0.736667        0.762496     0.844017  \n",
       "Multinomial Naive Bayes        0.716667        0.722820     0.915598  \n",
       "Predict only \"Suggested\"       0.630000        0.644647     0.907051  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_df.groupby(by='model').mean().sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.919668</td>\n",
       "      <td>0.996089</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.779369</td>\n",
       "      <td>0.935096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag of Words</th>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.799430</td>\n",
       "      <td>0.882212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document Embeddings</th>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.716464</td>\n",
       "      <td>0.944693</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.657882</td>\n",
       "      <td>0.890224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_accuracy  train_precision  train_recall  \\\n",
       "data                                                                 \n",
       "TF-IDF                     0.940333         0.919668      0.996089   \n",
       "Bag of Words               0.936000         0.919038      0.990223   \n",
       "Document Embeddings        0.715000         0.716464      0.944693   \n",
       "None                       0.626000         0.625753      0.928492   \n",
       "\n",
       "                     test_accuracy  test_precision  test_recall  \n",
       "data                                                             \n",
       "TF-IDF                       0.791        0.779369     0.935096  \n",
       "Bag of Words                 0.784        0.799430     0.882212  \n",
       "Document Embeddings          0.640        0.657882     0.890224  \n",
       "None                         0.630        0.644647     0.907051  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_df.groupby(by='data').mean().sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need to do this for preliminaries, just add this into final notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rf =  Pipeline([('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "              ('Random Forest', RandomForestClassifier(n_estimators=100))])\n",
    "svc = Pipeline([('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "                ('Support Vector Machine', SVC())])\n",
    "lr = Pipeline([('Word2Vec Vectorizer', W2vVectorizer(glove)),\n",
    "              ('Logistic Regression', LogisticRegression())])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "models = [('Random Forest', rf),\n",
    "          ('Support Vector Machine', svc),\n",
    "          ('Logistic Regression', lr)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "scores = [(name, cross_val_score(model, X_train_tokenized, y_train.values, cv=2).mean()) for name, model, in models]\n",
    "scores\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need to do this for preliminaries, just add this into final notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
