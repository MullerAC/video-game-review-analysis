{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(X_train, y_train, X_test, y_test, model, model_name, data_name):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    y_test_hat = model.predict(X_test)\n",
    "    \n",
    "    acc_train = accuracy_score(y_train, y_train_hat)\n",
    "    pre_train = precision_score(y_train, y_train_hat)\n",
    "    rec_train = recall_score(y_train, y_train_hat)\n",
    "    \n",
    "    acc_test = accuracy_score(y_test, y_test_hat)\n",
    "    pre_test = precision_score(y_test, y_test_hat)\n",
    "    rec_test = recall_score(y_test, y_test_hat)\n",
    "    \n",
    "    metrics = {'Model': model_name,\n",
    "               'Processing': data_name,\n",
    "               'Test Accuracy': acc_test,\n",
    "               'Test Precision': pre_test,\n",
    "               'Test Recall': rec_test,\n",
    "               'Train Accuracy': acc_train,\n",
    "               'Train Precision': pre_train,\n",
    "               'Train Recall': rec_train}\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [('TF-IDF', 'tf'),\n",
    "        ('TF-IDF with Bigrams', 'bigram'),\n",
    "        ('Document Embeddings', 'embed')]\n",
    "models = [('Logistic Regression', LogisticRegression(solver='saga')),\n",
    "          ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "          ('Random Forest', RandomForestClassifier())]\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_feather('../data/processed/y_train.feather')['voted_up'].to_numpy()\n",
    "y_test = pd.read_feather('../data/processed/y_test.feather')['voted_up'].to_numpy()\n",
    "\n",
    "for data_name, file in datasets:\n",
    "    X_train = pd.read_feather(f'../data/processed/X_train_{file}.feather').to_numpy()\n",
    "    X_test = pd.read_feather(f'../data/processed/X_test_{file}.feather').to_numpy()\n",
    "    for model_name, model in models:\n",
    "        print(model_name, data_name)\n",
    "        metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, model, model_name, data_name))\n",
    "\n",
    "metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, DummyClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.sort_values(by='Test Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_feather('../data/processed/y_train.feather')['voted_up'].to_numpy()\n",
    "X_train = pd.read_feather('../data/processed/X_train_bigram.feather').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'class_weight': None, 'solver': 'saga'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_lr = {'C': [0.1, 1, 10],\n",
    "                 'class_weight': ['balanced', None],\n",
    "                 'solver': ['saga']}\n",
    "gs_lr = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid_lr, scoring='accuracy', verbose=1)\n",
    "gs_lr.fit(X_train, y_train)\n",
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END class_weight=balanced, max_features=auto, n_estimators=100; total time= 5.8min\n",
      "[CV 2/3] END class_weight=balanced, max_features=auto, n_estimators=100; total time= 5.8min\n",
      "[CV 3/3] END class_weight=balanced, max_features=auto, n_estimators=100; total time= 5.6min\n",
      "[CV 1/3] END class_weight=balanced, max_features=auto, n_estimators=250; total time=13.7min\n",
      "[CV 2/3] END class_weight=balanced, max_features=auto, n_estimators=250; total time=13.8min\n",
      "[CV 3/3] END class_weight=balanced, max_features=auto, n_estimators=250; total time=13.5min\n",
      "[CV 1/3] END class_weight=balanced, max_features=150, n_estimators=100; total time= 8.2min\n",
      "[CV 2/3] END class_weight=balanced, max_features=150, n_estimators=100; total time= 8.3min\n",
      "[CV 3/3] END class_weight=balanced, max_features=150, n_estimators=100; total time= 8.2min\n",
      "[CV 1/3] END class_weight=balanced, max_features=150, n_estimators=250; total time=20.3min\n",
      "[CV 2/3] END class_weight=balanced, max_features=150, n_estimators=250; total time=20.6min\n",
      "[CV 3/3] END class_weight=balanced, max_features=150, n_estimators=250; total time=20.6min\n",
      "[CV 1/3] END class_weight=None, max_features=auto, n_estimators=100; total time=10.9min\n",
      "[CV 2/3] END class_weight=None, max_features=auto, n_estimators=100; total time=11.0min\n",
      "[CV 3/3] END class_weight=None, max_features=auto, n_estimators=100; total time=11.1min\n",
      "[CV 1/3] END class_weight=None, max_features=auto, n_estimators=250; total time=27.4min\n",
      "[CV 2/3] END class_weight=None, max_features=auto, n_estimators=250; total time=28.5min\n",
      "[CV 3/3] END class_weight=None, max_features=auto, n_estimators=250; total time=27.7min\n",
      "[CV 1/3] END class_weight=None, max_features=150, n_estimators=100; total time=17.9min\n",
      "[CV 2/3] END class_weight=None, max_features=150, n_estimators=100; total time=17.7min\n",
      "[CV 3/3] END class_weight=None, max_features=150, n_estimators=100; total time=17.5min\n",
      "[CV 1/3] END class_weight=None, max_features=150, n_estimators=250; total time=43.5min\n",
      "[CV 2/3] END class_weight=None, max_features=150, n_estimators=250; total time=44.6min\n",
      "[CV 3/3] END class_weight=None, max_features=150, n_estimators=250; total time=44.1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': None, 'max_features': 150, 'n_estimators': 100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_rf = {'n_estimators': [100, 250],\n",
    "                 'max_features': ['auto', 150],\n",
    "                 'class_weight': ['balanced', None]}\n",
    "gs_rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid_rf, scoring='accuracy', cv=3, verbose=5)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_feather('../data/processed/y_train.feather')['voted_up'].to_numpy()\n",
    "y_test = pd.read_feather('../data/processed/y_test.feather')['voted_up'].to_numpy()\n",
    "X_train = pd.read_feather(f'../data/processed/X_train_bigram.feather').to_numpy()\n",
    "X_test = pd.read_feather(f'../data/processed/X_test_bigram.feather').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Logistic Regression model\n",
      "starting Naive Bayes model\n",
      "starting Random Forest model\n",
      "completed models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Processing</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.914090</td>\n",
       "      <td>0.934010</td>\n",
       "      <td>0.961287</td>\n",
       "      <td>0.947295</td>\n",
       "      <td>0.956907</td>\n",
       "      <td>0.978674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.871614</td>\n",
       "      <td>0.869202</td>\n",
       "      <td>0.989558</td>\n",
       "      <td>0.877557</td>\n",
       "      <td>0.874733</td>\n",
       "      <td>0.989815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.866963</td>\n",
       "      <td>0.864709</td>\n",
       "      <td>0.989727</td>\n",
       "      <td>0.998957</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model           Processing  Test Accuracy  \\\n",
       "0      Logistic Regression  TF-IDF with Bigrams       0.914090   \n",
       "1  Multinomial Naive Bayes  TF-IDF with Bigrams       0.871614   \n",
       "2            Random Forest  TF-IDF with Bigrams       0.866963   \n",
       "\n",
       "   Test Precision  Test Recall  Train Accuracy  Train Precision  Train Recall  \n",
       "0        0.934010     0.961287        0.947295         0.956907      0.978674  \n",
       "1        0.869202     0.989558        0.877557         0.874733      0.989815  \n",
       "2        0.864709     0.989727        0.998957         0.998940      0.999767  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression(C=10, solver='saga')\n",
    "nb_final = MultinomialNB()\n",
    "rf_final = RandomForestClassifier(max_features=150)\n",
    "\n",
    "final_metrics = []\n",
    "print('starting Logistic Regression model')\n",
    "final_metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, lr_final, 'Logistic Regression', 'TF-IDF with Bigrams'))\n",
    "print('starting Naive Bayes model')\n",
    "final_metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, nb_final, 'Multinomial Naive Bayes', 'TF-IDF with Bigrams'))\n",
    "print('starting Random Forest model')\n",
    "final_metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, rf_final, 'Random Forest', 'TF-IDF with Bigrams'))\n",
    "print('completed models')\n",
    "\n",
    "final_metrics_df = pd.DataFrame(final_metrics)\n",
    "final_metrics_df.sort_values(by='Test Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
