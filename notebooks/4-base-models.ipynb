{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This processed data is not uploaded to the Github repo, as some of the files are too large. Run notebook 2 in order to produce the same files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I ran this type of model analysis with the sample data, I want to run it again now that I've created bigrams. I'm also no longer using SVM, as it took way too long to run even on the smaller dataset. Once again, logistic regression is the best performing model. Also as expected, bigrams improved the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(X_train, y_train, X_test, y_test, model, model_name, data_name):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_hat = model.predict(X_train)\n",
    "    y_test_hat = model.predict(X_test)\n",
    "    \n",
    "    acc_train = accuracy_score(y_train, y_train_hat)\n",
    "    pre_train = precision_score(y_train, y_train_hat)\n",
    "    rec_train = recall_score(y_train, y_train_hat)\n",
    "    f1_train = f1_score(y_train, y_train_hat, average='macro')\n",
    "    \n",
    "    acc_test = accuracy_score(y_test, y_test_hat)\n",
    "    pre_test = precision_score(y_test, y_test_hat)\n",
    "    rec_test = recall_score(y_test, y_test_hat)\n",
    "    f1_test = f1_score(y_test, y_test_hat, average='macro')\n",
    "    \n",
    "    metrics = {'Model': model_name,\n",
    "               'Processing': data_name,\n",
    "               'Test Accuracy': acc_test,\n",
    "               'Test Precision': pre_test,\n",
    "               'Test Recall': rec_test,\n",
    "               'Test F1': f1_test,\n",
    "               'Train Accuracy': acc_train,\n",
    "               'Train Precision': pre_train,\n",
    "               'Train Recall': rec_train,\n",
    "               'Train F1': f1_train}\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "datasets = [('TF-IDF', 'tf'),\n",
    "        ('TF-IDF with Bigrams', 'bigram'),\n",
    "        ('Document Embeddings', 'embed')]\n",
    "\"\"\"\n",
    "datasets = [('TF-IDF with Bigrams', 'bigram')]\n",
    "models = [('Logistic Regression', LogisticRegression(solver='saga')),\n",
    "          ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "          ('Random Forest', RandomForestClassifier())]\n",
    "metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression TF-IDF with Bigrams\n",
      "Multinomial Naive Bayes TF-IDF with Bigrams\n",
      "Random Forest TF-IDF with Bigrams\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_model_metrics() missing 2 required positional arguments: 'model_name' and 'data_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bc48a8395024>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_model_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_model_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDummyClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: get_model_metrics() missing 2 required positional arguments: 'model_name' and 'data_name'"
     ]
    }
   ],
   "source": [
    "y_train = pd.read_pickle('../data/processed/y_train.pkl.gz')['voted_up'].to_numpy()\n",
    "y_test = pd.read_pickle('../data/processed/y_test.pkl.gz')['voted_up'].to_numpy()\n",
    "\n",
    "for data_name, file in datasets:\n",
    "    X_train = pd.read_pickle(f'../data/processed/X_{file}_train.pkl.gz').to_numpy()\n",
    "    X_test = pd.read_pickle(f'../data/processed/X_{file}_test.pkl.gz').to_numpy()\n",
    "    for model_name, model in models:\n",
    "        print(model_name, data_name)\n",
    "        metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, model, model_name, data_name))\n",
    "\n",
    "metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, DummyClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Processing</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.841855</td>\n",
       "      <td>0.864672</td>\n",
       "      <td>0.928968</td>\n",
       "      <td>0.843095</td>\n",
       "      <td>0.865643</td>\n",
       "      <td>0.929798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.822884</td>\n",
       "      <td>0.825431</td>\n",
       "      <td>0.960816</td>\n",
       "      <td>0.987273</td>\n",
       "      <td>0.985017</td>\n",
       "      <td>0.997777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.761805</td>\n",
       "      <td>0.756041</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>0.762755</td>\n",
       "      <td>0.756878</td>\n",
       "      <td>0.995376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model           Processing  Test Accuracy  \\\n",
       "0      Logistic Regression  TF-IDF with Bigrams       0.841855   \n",
       "2            Random Forest  TF-IDF with Bigrams       0.822884   \n",
       "1  Multinomial Naive Bayes  TF-IDF with Bigrams       0.761805   \n",
       "\n",
       "   Test Precision  Test Recall  Train Accuracy  Train Precision  Train Recall  \n",
       "0        0.864672     0.928968        0.843095         0.865643      0.929798  \n",
       "2        0.825431     0.960816        0.987273         0.985017      0.997777  \n",
       "1        0.756041     0.995139        0.762755         0.756878      0.995376  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.sort_values(by='Test Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I performed a gridsearch on the random forest and logistic regression models using just the bigram data, as it performed the best. Naive Bayes models do not have any hyperparameters to tune, and so there is no grid search to perform on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle('../data/processed/y_train.pkl.gz')['voted_up'].to_numpy()\n",
    "X_train = pd.read_pickle('../data/processed/X_bigram_train.pkl.gz').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ......C=0.1, class_weight=balanced, solver=saga; total time= 4.5min\n",
      "[CV 2/5] END ......C=0.1, class_weight=balanced, solver=saga; total time= 4.0min\n",
      "[CV 3/5] END ......C=0.1, class_weight=balanced, solver=saga; total time= 4.2min\n",
      "[CV 4/5] END ......C=0.1, class_weight=balanced, solver=saga; total time= 3.9min\n",
      "[CV 5/5] END ......C=0.1, class_weight=balanced, solver=saga; total time= 4.7min\n",
      "[CV 1/5] END ..........C=0.1, class_weight=None, solver=saga; total time= 3.8min\n",
      "[CV 2/5] END ..........C=0.1, class_weight=None, solver=saga; total time= 3.6min\n",
      "[CV 3/5] END ..........C=0.1, class_weight=None, solver=saga; total time= 3.9min\n",
      "[CV 4/5] END ..........C=0.1, class_weight=None, solver=saga; total time= 3.8min\n",
      "[CV 5/5] END ..........C=0.1, class_weight=None, solver=saga; total time= 3.7min\n",
      "[CV 1/5] END ........C=1, class_weight=balanced, solver=saga; total time= 4.0min\n",
      "[CV 2/5] END ........C=1, class_weight=balanced, solver=saga; total time= 4.5min\n",
      "[CV 3/5] END ........C=1, class_weight=balanced, solver=saga; total time= 4.1min\n",
      "[CV 4/5] END ........C=1, class_weight=balanced, solver=saga; total time= 4.1min\n",
      "[CV 5/5] END ........C=1, class_weight=balanced, solver=saga; total time= 4.1min\n",
      "[CV 1/5] END ............C=1, class_weight=None, solver=saga; total time= 3.9min\n",
      "[CV 2/5] END ............C=1, class_weight=None, solver=saga; total time= 3.7min\n",
      "[CV 3/5] END ............C=1, class_weight=None, solver=saga; total time= 3.8min\n",
      "[CV 4/5] END ............C=1, class_weight=None, solver=saga; total time= 3.8min\n",
      "[CV 5/5] END ............C=1, class_weight=None, solver=saga; total time= 3.8min\n",
      "[CV 1/5] END .......C=10, class_weight=balanced, solver=saga; total time= 4.4min\n",
      "[CV 2/5] END .......C=10, class_weight=balanced, solver=saga; total time= 4.5min\n",
      "[CV 3/5] END .......C=10, class_weight=balanced, solver=saga; total time= 4.6min\n",
      "[CV 4/5] END .......C=10, class_weight=balanced, solver=saga; total time= 4.5min\n",
      "[CV 5/5] END .......C=10, class_weight=balanced, solver=saga; total time= 4.4min\n",
      "[CV 1/5] END ...........C=10, class_weight=None, solver=saga; total time= 5.2min\n",
      "[CV 2/5] END ...........C=10, class_weight=None, solver=saga; total time= 4.7min\n",
      "[CV 3/5] END ...........C=10, class_weight=None, solver=saga; total time= 4.2min\n",
      "[CV 4/5] END ...........C=10, class_weight=None, solver=saga; total time= 4.6min\n",
      "[CV 5/5] END ...........C=10, class_weight=None, solver=saga; total time= 4.4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'class_weight': None, 'solver': 'saga'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_lr = {'C': [0.1, 1, 10],\n",
    "                 'class_weight': ['balanced', None],\n",
    "                 'solver': ['saga']}\n",
    "gs_lr = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid_lr, scoring='f1_macro', cv=3, verbose=5)\n",
    "gs_lr.fit(X_train, y_train)\n",
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV 1/3] END class_weight=balanced, max_features=auto, n_estimators=100; total time=33.3min\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {'n_estimators': [100, 500],\n",
    "                 'max_features': ['auto', 150],\n",
    "                 'class_weight': ['balanced', None]}\n",
    "gs_rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid_rf, scoring='f1_macro', cv=3, verbose=5)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing the best tuned models, logistic regression still has the best accuracy. I had expected random forest to improve performance more with tuning, but it seems not to be the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle('../data/processed/y_train.pkl.gz')['voted_up'].to_numpy()\n",
    "y_test = pd.read_pickle('../data/processed/y_test.pkl.gz')['voted_up'].to_numpy()\n",
    "X_train = pd.read_pickle('../data/processed/X_bigram_train.pkl.gz').to_numpy()\n",
    "X_test = pd.read_pickle('../data/processed/X_bigram_test.pkl.gz').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Logistic Regression', 'Processing': 'TF-IDF with Bigrams', 'Test Accuracy': 0.8419409987277354, 'Test Precision': 0.865303327471933, 'Test Recall': 0.9281795511221945, 'Test F1': 0.7850249727016845, 'Train Accuracy': 0.8431205218571709, 'Train Precision': 0.8662267959126413, 'Train Recall': 0.9289829863564711, 'Train F1': 0.7862350301545274}\n"
     ]
    }
   ],
   "source": [
    "lr_final = LogisticRegression(C=10, solver='saga')\n",
    "metrics = get_model_metrics(X_train, y_train, X_test, y_test, lr_final, 'Logistic Regression', 'TF-IDF with Bigrams')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': 'Logistic Regression',\n",
       " 'Processing': 'TF-IDF with Bigrams',\n",
       " 'Test Accuracy': 0.8419409987277354,\n",
       " 'Test Precision': 0.865303327471933,\n",
       " 'Test Recall': 0.9281795511221945,\n",
       " 'Test F1': 0.7850249727016845,\n",
       " 'Train Accuracy': 0.8431205218571709,\n",
       " 'Train Precision': 0.8662267959126413,\n",
       " 'Train Recall': 0.9289829863564711,\n",
       " 'Train F1': 0.7862350301545274}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting Logistic Regression model\n",
      "starting Naive Bayes model\n",
      "starting Random Forest model\n",
      "completed models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Processing</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.914090</td>\n",
       "      <td>0.934010</td>\n",
       "      <td>0.961287</td>\n",
       "      <td>0.947295</td>\n",
       "      <td>0.956907</td>\n",
       "      <td>0.978674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.871614</td>\n",
       "      <td>0.869202</td>\n",
       "      <td>0.989558</td>\n",
       "      <td>0.877557</td>\n",
       "      <td>0.874733</td>\n",
       "      <td>0.989815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF with Bigrams</td>\n",
       "      <td>0.866963</td>\n",
       "      <td>0.864709</td>\n",
       "      <td>0.989727</td>\n",
       "      <td>0.998957</td>\n",
       "      <td>0.998940</td>\n",
       "      <td>0.999767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model           Processing  Test Accuracy  \\\n",
       "0      Logistic Regression  TF-IDF with Bigrams       0.914090   \n",
       "1  Multinomial Naive Bayes  TF-IDF with Bigrams       0.871614   \n",
       "2            Random Forest  TF-IDF with Bigrams       0.866963   \n",
       "\n",
       "   Test Precision  Test Recall  Train Accuracy  Train Precision  Train Recall  \n",
       "0        0.934010     0.961287        0.947295         0.956907      0.978674  \n",
       "1        0.869202     0.989558        0.877557         0.874733      0.989815  \n",
       "2        0.864709     0.989727        0.998957         0.998940      0.999767  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final = LogisticRegression(C=10, solver='saga')\n",
    "nb_final = MultinomialNB()\n",
    "rf_final = RandomForestClassifier(max_features=150)\n",
    "\n",
    "final_metrics = []\n",
    "print('starting Logistic Regression model')\n",
    "final_metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, lr_final, 'Logistic Regression', 'TF-IDF with Bigrams'))\n",
    "print('starting Naive Bayes model')\n",
    "final_metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, nb_final, 'Multinomial Naive Bayes', 'TF-IDF with Bigrams'))\n",
    "print('starting Random Forest model')\n",
    "final_metrics.append(get_model_metrics(X_train, y_train, X_test, y_test, rf_final, 'Random Forest', 'TF-IDF with Bigrams'))\n",
    "print('completed models')\n",
    "\n",
    "final_metrics_df = pd.DataFrame(final_metrics)\n",
    "final_metrics_df.sort_values(by='Test Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I will also be creating a neural network model, I still want to save this best logistic regression model. I can try to use it as a backup in case the neural network model is too big to upload to heroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_pickle('../data/processed/y_train.pkl.gz')['voted_up'].to_numpy()\n",
    "y_test = pd.read_pickle('../data/processed/y_test.pkl.gz')['voted_up'].to_numpy()\n",
    "X_train = pd.read_pickle('../data/processed/X_bigram_train.pkl.gz').to_numpy()\n",
    "X_test = pd.read_pickle('../data/processed/X_bigram_test.pkl.gz').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, solver='saga')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=10, solver='saga')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('../final_model/sklearn-logreg/model.pk', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
