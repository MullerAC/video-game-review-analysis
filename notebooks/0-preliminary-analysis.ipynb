{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start this project by collecting some initial data to work with. These cells collect 2000 reviews from a single game. I then store the reviews in a dataframe and save in a feather format, as the file size for feather files is a lot smaller than for csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(appid, params):\n",
    "        url_start = 'https://store.steampowered.com/appreviews/'\n",
    "        response = requests.get(url=url_start+appid, params=params)\n",
    "        return response.json() # return data extracted from the json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appid = '1091500' # Cyberpunk 2077, good mix of positive and negative, just for samples\n",
    "cursor = '*'\n",
    "params = { # https://partner.steamgames.com/doc/store/getreviews\n",
    "        'json' : 1,\n",
    "        'filter' : 'all', # sort by: recent, updated, all (helpfullness)\n",
    "        'language' : 'english', # https://partner.steamgames.com/doc/store/localization\n",
    "        'day_range' : 9223372036854775807, # shows reveiws from all time\n",
    "        'cursor' : cursor.encode(), # for pagination\n",
    "        'review_type' : 'all', # all, positive, negative\n",
    "        'purchase_type' : 'all', # all, non_steam_purchase, steam\n",
    "        'num_per_page' : 100 # max amount per request\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(n//100):\n",
    "    result = get_reviews(appid, params)\n",
    "    results += result['reviews']\n",
    "    params['cursor'] = result['cursor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.DataFrame(results)[['review', 'voted_up']]\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['voted_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_feather('data/sample_reviews.feather', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I read in the sample data and perform the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>voted_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>While it does feel like they needed a bit more...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Game is asbolutely good. The Night City is som...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This game has a JoJo reference.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheers everyone, after 8 years we finally made...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>made my penis to perfection in a call with fri...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>The game doesn't bring anything new to the tab...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>pp go smol ( ͡° ͜ʖ ͡°)\\n\\npp go big (˵ ͡☉ ͜ʖ ͡...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Great characters, nice city, thrilling storyli...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>So here is my review after all of this time.\\n...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Here's the headline: If you enjoy Far Cry, Tom...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  voted_up\n",
       "0     While it does feel like they needed a bit more...      True\n",
       "1     Game is asbolutely good. The Night City is som...      True\n",
       "2                       This game has a JoJo reference.      True\n",
       "3     Cheers everyone, after 8 years we finally made...      True\n",
       "4     made my penis to perfection in a call with fri...      True\n",
       "...                                                 ...       ...\n",
       "1995  The game doesn't bring anything new to the tab...     False\n",
       "1996  pp go smol ( ͡° ͜ʖ ͡°)\\n\\npp go big (˵ ͡☉ ͜ʖ ͡...      True\n",
       "1997  Great characters, nice city, thrilling storyli...      True\n",
       "1998  So here is my review after all of this time.\\n...      True\n",
       "1999  Here's the headline: If you enjoy Far Cry, Tom...      True\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv('data/sample_reviews.feather')\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   review    2000 non-null   object\n",
      " 1   voted_up  2000 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 17.7+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500,), (1500,), (500,), (500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(reviews_df, random_state=212)\n",
    "X_train, y_train = df_train['review'], df_train['voted_up']\n",
    "X_test, y_test = df_test['review'], df_test['voted_up']\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I run through the pre-processing and feature engineering steps I think I might use with the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Regexp Tokenizer allows me to match only latin characters and digits. Steam reviews have a language option, but even English-marked reviews are often written in other languages. At the same time, I remove markdown tags from the taxt, as well as punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_list = list(punctuation) + ['`', '’', '…']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(review):\n",
    "    review = re.sub(r'\\[.*?\\]', '', review) # remove markdown tags, only needed for Steam reviews\n",
    "    review = review.translate(str.maketrans('', '', ''.join(punctuation_list))) # remove all punctuation\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+') # tokenize words with only numbers and latin characters\n",
    "    return tokenizer.tokenize(review.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized = list(map(tokenize, X_train))\n",
    "X_test_tokenized = list(map(tokenize, X_test))\n",
    "len(X_train_tokenized), len(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop-Words Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english') + punctuation_list\n",
    "len(stopwords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stopworded = [[word for word in review if word not in stopwords_list] for review in X_train_tokenized]\n",
    "X_test_stopworded = [[word for word in review if word not in stopwords_list] for review in X_test_tokenized]\n",
    "len(X_train_stopworded), len(X_test_stopworded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer() \n",
    "X_train_lemmatized = [list(map(lemmatizer.lemmatize, review)) for review in X_train_stopworded]\n",
    "X_test_lemmatized = [list(map(lemmatizer.lemmatize, review)) for review in X_test_stopworded]\n",
    "len(X_train_lemmatized), len(X_test_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed = [' '.join(review) for review in X_train_lemmatized]\n",
    "X_test_preprocessed = [' '.join(review) for review in X_test_lemmatized]\n",
    "X_train_split = [review.split(' ') for review in X_train_preprocessed]\n",
    "X_test_split = [review.split(' ') for review in X_test_preprocessed]\n",
    "len(X_train_preprocessed), len(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 12529), (500, 12529))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train_bow = pd.DataFrame(cv.fit_transform(X_train_preprocessed).todense(), columns=cv.get_feature_names())\n",
    "X_test_bow = pd.DataFrame(cv.transform(X_test_preprocessed).todense(), columns=cv.get_feature_names())\n",
    "X_train_bow.shape, X_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Vectorizer also allows for n-gram creation, which I will use in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 12529), (500, 12529))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "X_train_tf = pd.DataFrame(tf.fit_transform(X_train_preprocessed).todense(), columns=tf.get_feature_names())\n",
    "X_test_tf = pd.DataFrame(tf.transform(X_test_preprocessed).todense(), columns=tf.get_feature_names())\n",
    "X_train_tf.shape, X_test_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to come back to this and try spacy's document embedding, but this one is easier to use, as it functions just like an sklearn model/transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.sklearn_api import D2VTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 100), (500, 100))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = D2VTransformer()\n",
    "scaler = MinMaxScaler((1, 2)) # scaled to prevent negative values, which do not work with Naive Bayes models\n",
    "X_train_embed = scaler.fit_transform(pd.DataFrame(vectorizer.fit_transform(X_train_split)))\n",
    "X_test_embed = scaler.transform(pd.DataFrame(vectorizer.transform(X_test_split)))\n",
    "X_train_embed.shape, X_test_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't perform an EDA on the sample data, but this is where in the process it would occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trial a few sklearn classifier models here on each of my processing methods. The big takaways are that TF-IDF is the best performer, and gensim document embeddings greatly underperformed. In terms of models, Logistic Regression actually performed the best. SVM also performed well, but it took so long to run that I won't be attempting it on the larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_train, y_hat_train, y_test, y_hat_test):\n",
    "    train_accuracy = accuracy_score(y_train, y_hat_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_hat_test)\n",
    "    train_precision = precision_score(y_train, y_hat_train)\n",
    "    test_precision = precision_score(y_test, y_hat_test)\n",
    "    train_recall = recall_score(y_train, y_hat_train)\n",
    "    test_recall = recall_score(y_test, y_hat_test)\n",
    "    \n",
    "    print('\\t\\tAccuracy\\tPrecision\\tRecall')\n",
    "    print(f'Training:\\t{round(train_accuracy, 2)}\\t\\t{round(train_precision, 2)}\\t\\t{round(train_recall, 2)}')\n",
    "    print(f'Testing:\\t{round(test_accuracy, 2)}\\t\\t{round(test_precision, 2)}\\t\\t{round(test_recall, 2)}')\n",
    "    \n",
    "    return {'train_accuracy':train_accuracy, 'train_precision':train_precision, 'train_recall':train_recall,\n",
    "            'test_accuracy':test_accuracy, 'test_precision':test_precision, 'test_recall':test_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.596667\n",
       "False    0.403333\n",
       "Name: voted_up, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = [True]*len(y_train)\n",
    "test_preds = [True]*len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict only \"Suggested\"\tNone\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.63\t\t0.63\t\t0.93\n",
      "Testing:\t0.63\t\t0.64\t\t0.91\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Predict only \"Suggested\"'\n",
    "data_name = 'None'\n",
    "print(f'{model_name}\\t{data_name}')\n",
    "metrics = {'model':model_name, 'data':data_name}\n",
    "metrics.update(get_metrics(y_train, train_preds, y_test, test_preds))\n",
    "model_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Logistic Regression', LogisticRegression),\n",
    "          ('Multinomial Naive Bayes', MultinomialNB),\n",
    "          ('Random Forest', RandomForestClassifier),\n",
    "          ('Support Vector Machines', SVC)]\n",
    "datasets = [('Bag of Words', X_train_bow, X_test_bow),\n",
    "             ('TF-IDF', X_train_tf, X_test_tf),\n",
    "             ('Document Embeddings', X_train_embed, X_test_embed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.98\t\t0.97\t\t1.0\n",
      "Testing:\t0.82\t\t0.84\t\t0.87\n",
      "\n",
      "Logistic Regression\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.92\t\t0.89\t\t0.98\n",
      "Testing:\t0.83\t\t0.81\t\t0.95\n",
      "\n",
      "Logistic Regression\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.63\t\t0.63\t\t0.93\n",
      "Testing:\t0.64\t\t0.65\t\t0.92\n",
      "\n",
      "Multinomial Naive Bayes\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.94\t\t0.93\t\t0.97\n",
      "Testing:\t0.8\t\t0.83\t\t0.86\n",
      "\n",
      "Multinomial Naive Bayes\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.85\t\t0.8\t\t1.0\n",
      "Testing:\t0.73\t\t0.71\t\t0.98\n",
      "\n",
      "Multinomial Naive Bayes\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.6\t\t0.61\t\t0.92\n",
      "Testing:\t0.61\t\t0.63\t\t0.91\n",
      "\n",
      "Random Forest\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t1.0\t\t1.0\n",
      "Testing:\t0.77\t\t0.81\t\t0.82\n",
      "\n",
      "Random Forest\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t1.0\t\t1.0\n",
      "Testing:\t0.77\t\t0.78\t\t0.88\n",
      "\n",
      "Random Forest\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t1.0\t\t1.0\n",
      "Testing:\t0.67\t\t0.7\t\t0.82\n",
      "\n",
      "Support Vector Machines\t\tBag of Words\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.82\t\t0.78\t\t0.99\n",
      "Testing:\t0.75\t\t0.72\t\t0.97\n",
      "\n",
      "Support Vector Machines\t\tTF-IDF\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t1.0\t\t0.99\t\t1.0\n",
      "Testing:\t0.83\t\t0.82\t\t0.93\n",
      "\n",
      "Support Vector Machines\t\tDocument Embeddings\n",
      "\t\tAccuracy\tPrecision\tRecall\n",
      "Training:\t0.63\t\t0.63\t\t0.93\n",
      "Testing:\t0.63\t\t0.64\t\t0.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models:\n",
    "    for data_name, X_train, X_test in datasets:\n",
    "        classifier = model()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        train_preds = classifier.predict(X_train)\n",
    "        test_preds = classifier.predict(X_test)\n",
    "\n",
    "        print(f'{model_name}\\t\\t{data_name}')\n",
    "        metrics = {'model':model_name, 'data':data_name}\n",
    "        metrics.update(get_metrics(y_train, train_preds, y_test, test_preds))\n",
    "        print()\n",
    "        model_metrics.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.992239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.819718</td>\n",
       "      <td>0.932692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.920667</td>\n",
       "      <td>0.893509</td>\n",
       "      <td>0.984358</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.810440</td>\n",
       "      <td>0.945513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.972826</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.929336</td>\n",
       "      <td>0.969832</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.862179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.996659</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.997768</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.805643</td>\n",
       "      <td>0.823718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>0.824667</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.992179</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.724880</td>\n",
       "      <td>0.971154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.847333</td>\n",
       "      <td>0.796263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.707657</td>\n",
       "      <td>0.977564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.823718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>0.632000</td>\n",
       "      <td>0.629239</td>\n",
       "      <td>0.932961</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.651584</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Predict only \"Suggested\"</td>\n",
       "      <td>None</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>Document Embeddings</td>\n",
       "      <td>0.602000</td>\n",
       "      <td>0.610863</td>\n",
       "      <td>0.917318</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.633110</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model                 data  train_accuracy  \\\n",
       "11   Support Vector Machines               TF-IDF        0.995333   \n",
       "2        Logistic Regression               TF-IDF        0.920667   \n",
       "1        Logistic Regression         Bag of Words        0.983333   \n",
       "4    Multinomial Naive Bayes         Bag of Words        0.938000   \n",
       "8              Random Forest               TF-IDF        0.998000   \n",
       "7              Random Forest         Bag of Words        0.998000   \n",
       "10   Support Vector Machines         Bag of Words        0.824667   \n",
       "5    Multinomial Naive Bayes               TF-IDF        0.847333   \n",
       "9              Random Forest  Document Embeddings        1.000000   \n",
       "3        Logistic Regression  Document Embeddings        0.632000   \n",
       "0   Predict only \"Suggested\"                 None        0.626000   \n",
       "12   Support Vector Machines  Document Embeddings        0.626000   \n",
       "6    Multinomial Naive Bayes  Document Embeddings        0.602000   \n",
       "\n",
       "    train_precision  train_recall  test_accuracy  test_precision  test_recall  \n",
       "11         0.992239      1.000000          0.830        0.819718     0.932692  \n",
       "2          0.893509      0.984358          0.828        0.810440     0.945513  \n",
       "1          0.972826      1.000000          0.816        0.839506     0.871795  \n",
       "4          0.929336      0.969832          0.802        0.827692     0.862179  \n",
       "8          0.996659      1.000000          0.772        0.779661     0.884615  \n",
       "7          0.997768      0.998883          0.766        0.805643     0.823718  \n",
       "10         0.776224      0.992179          0.752        0.724880     0.971154  \n",
       "5          0.796263      1.000000          0.734        0.707657     0.977564  \n",
       "9          1.000000      1.000000          0.672        0.702186     0.823718  \n",
       "3          0.629239      0.932961          0.644        0.651584     0.923077  \n",
       "0          0.625753      0.928492          0.630        0.644647     0.907051  \n",
       "12         0.625753      0.928492          0.630        0.644647     0.907051  \n",
       "6          0.610863      0.917318          0.614        0.633110     0.907051  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_df = pd.DataFrame(model_metrics)\n",
    "model_metrics_df.sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.845333</td>\n",
       "      <td>0.831858</td>\n",
       "      <td>0.972439</td>\n",
       "      <td>0.762667</td>\n",
       "      <td>0.767176</td>\n",
       "      <td>0.913462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.798072</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>0.729749</td>\n",
       "      <td>0.936966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.999628</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.762496</td>\n",
       "      <td>0.844017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <td>0.795778</td>\n",
       "      <td>0.778821</td>\n",
       "      <td>0.962384</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.722820</td>\n",
       "      <td>0.915598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predict only \"Suggested\"</th>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          train_accuracy  train_precision  train_recall  \\\n",
       "model                                                                     \n",
       "Logistic Regression             0.845333         0.831858      0.972439   \n",
       "Support Vector Machines         0.815333         0.798072      0.973557   \n",
       "Random Forest                   0.998667         0.998142      0.999628   \n",
       "Multinomial Naive Bayes         0.795778         0.778821      0.962384   \n",
       "Predict only \"Suggested\"        0.626000         0.625753      0.928492   \n",
       "\n",
       "                          test_accuracy  test_precision  test_recall  \n",
       "model                                                                 \n",
       "Logistic Regression            0.762667        0.767176     0.913462  \n",
       "Support Vector Machines        0.737333        0.729749     0.936966  \n",
       "Random Forest                  0.736667        0.762496     0.844017  \n",
       "Multinomial Naive Bayes        0.716667        0.722820     0.915598  \n",
       "Predict only \"Suggested\"       0.630000        0.644647     0.907051  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_df.groupby(by='model').mean().sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.940333</td>\n",
       "      <td>0.919668</td>\n",
       "      <td>0.996089</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.779369</td>\n",
       "      <td>0.935096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag of Words</th>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.919038</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.799430</td>\n",
       "      <td>0.882212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document Embeddings</th>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.716464</td>\n",
       "      <td>0.944693</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.657882</td>\n",
       "      <td>0.890224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.625753</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.644647</td>\n",
       "      <td>0.907051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_accuracy  train_precision  train_recall  \\\n",
       "data                                                                 \n",
       "TF-IDF                     0.940333         0.919668      0.996089   \n",
       "Bag of Words               0.936000         0.919038      0.990223   \n",
       "Document Embeddings        0.715000         0.716464      0.944693   \n",
       "None                       0.626000         0.625753      0.928492   \n",
       "\n",
       "                     test_accuracy  test_precision  test_recall  \n",
       "data                                                             \n",
       "TF-IDF                       0.791        0.779369     0.935096  \n",
       "Bag of Words                 0.784        0.799430     0.882212  \n",
       "Document Embeddings          0.640        0.657882     0.890224  \n",
       "None                         0.630        0.644647     0.907051  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_df.groupby(by='data').mean().sort_values(by='test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need to do this for preliminaries, just add this into final notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try these for the full dataset, but I'm not going to run these on this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim's LDA topic modeling is the first one to run through. I seperated the reviews by positive and negative reviews, but the results were more or less the same. In order to get this to a meaningful result, more work needs to be done. I need to remove tokens that have enough commonality between the two classes. This may also be good to try with bigrams, when I make those for the full dataset. For now, I won't bother adding this into the final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\capstone\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1500 non-null   object\n",
      " 1   1       1500 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 13.3+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\capstone\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\capstone\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_tmp = pd.DataFrame(zip(X_train_preprocessed, y_train))\n",
    "X_split_pos = [[word for word in review.split(' ')] for review in df_tmp.loc[df_tmp[1]][0].to_numpy()]\n",
    "X_split_neg = [[word for word in review.split(' ')] for review in df_tmp.loc[~df_tmp[1]][0].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\capstone\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el421215798953516247932935562\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el421215798953516247932935562_data = {\"mdsDat\": {\"x\": [0.1627760300407633, 0.05278566380876506, -0.005700444378334795, -0.13066814243248573, -0.0791931070387077], \"y\": [-0.02100040330067527, 0.014774951272497458, -0.011707611559319597, -0.07755007982141222, 0.09548314340890961], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [84.71106804811966, 5.393700761182334, 3.8362842702817423, 3.626368934252991, 2.432577986163278]}, \"tinfo\": {\"Term\": [\"game\", \"like\", \"bug\", \"really\", \"character\", \"world\", \"im\", \"also\", \"cyberpunk\", \"dont\", \"great\", \"city\", \"setting\", \"see\", \"make\", \"feel\", \"want\", \"thing\", \"much\", \"go\", \"got\", \"2077\", \"look\", \"night\", \"good\", \"still\", \"people\", \"patch\", \"big\", \"many\", \"fixed\", \"overall\", \"playthrough\", \"ending\", \"soon\", \"experience\", \"hopefully\", \"load\", \"main\", \"shooting\", \"took\", \"dialogue\", \"update\", \"enjoyable\", \"felt\", \"interaction\", \"rather\", \"choose\", \"havent\", \"large\", \"enjoyed\", \"bring\", \"awesome\", \"alone\", \"amazing\", \"cop\", \"breathtaking\", \"save\", \"side\", \"smooth\", \"story\", \"game\", \"quest\", \"hour\", \"lot\", \"good\", \"better\", \"graphic\", \"recommend\", \"definitely\", \"content\", \"cdpr\", \"one\", \"choice\", \"time\", \"feel\", \"get\", \"even\", \"world\", \"first\", \"bug\", \"character\", \"great\", \"around\", \"fun\", \"issue\", \"thing\", \"well\", \"city\", \"really\", \"like\", \"mission\", \"play\", \"cyberpunk\", \"would\", \"dont\", \"im\", \"still\", \"much\", \"also\", \"make\", \"cat\", \"pet\", \"ur\", \"vram\", \"engage\", \"scattering\", \"taxing\", \"aa\", \"subsurface\", \"pon\", \"despair\", \"cloud\", \"fov\", \"blue\", \"sikeyim\", \"tit\", \"genital\", \"cute\", \"2d\", \"plug\", \"ye\", \"statement\", \"fantasize\", \"05\", \"lisbon\", \"terrarium\", \"thru\", \"wreck\", \"dashboard\", \"cleaner\", \"boost\", \"volumetric\", \"fidelityfx\", \"packed\", \"vending\", \"reflection\", \"shadow\", \"implant\", \"u\", \"resolution\", \"lower\", \"craft\", \"might\", \"distracting\", \"quality\", \"c\", \"like\", \"big\", \"setting\", \"2\", \"performance\", \"also\", \"high\", \"ride\", \"game\", \"turn\", \"character\", \"bug\", \"gun\", \"make\", \"go\", \"really\", \"perk\", \"look\", \"different\", \"dont\", \"want\", \"car\", \"much\", \"thing\", \"feel\", \"3\", \"time\", \"city\", \"still\", \"get\", \"way\", \"cough\", \"esta\", \"tu\", \"porque\", \"custom\", \"donde\", \"una\", \"actitud\", \"vorpx\", \"remap\", \"remapping\", \"disgrace\", \"ddr4\", \"insult\", \"este\", \"bye\", \"code\", \"9910\", \"amrketing\", \"todo\", \"patada\", \"rico\", \"enga\", \"simplemente\", \"literalmente\", \"glowing\", \"estomago\", \"ver\", \"esperabas\", \"fake\", \"el\", \"juego\", \"del\", \"country\", \"family\", \"la\", \"vale\", \"que\", \"si\", \"key\", \"destroying\", \"de\", \"recommendation\", \"610\", \"wow\", \"e\", \"true\", \"1010\", \"game\", \"f\", \"pc\", \"really\", \"se\", \"world\", \"exist\", \"development\", \"see\", \"great\", \"there\", \"big\", \"work\", \"thats\", \"cyberpunk\", \"want\", \"many\", \"im\", \"people\", \"night\", \"back\", \"city\", \"story\", \"every\", \"good\", \"go\", \"need\", \"bug\", \"like\", \"bir\", \"bu\", \"g\", \"z\", \"ama\", \"nda\", \"oyun\", \"l\", \"un\", \"ki\", \"daha\", \"oynan\", \"yapma\", \"rol\", \"hi\", \"kadar\", \"ana\", \"olmas\", \"oyunun\", \"ayr\", \"harika\", \"olaylar\", \"olarak\", \"ba\", \"istiyorum\", \"yan\", \"var\", \"hissi\", \"cuerpo\", \"tatmin\", \"ya\", \"n\", \"en\", \"muy\", \"los\", \"k\", \"lo\", \"que\", \"de\", \"el\", \"la\", \"juego\", \"e\", \"ok\", \"game\", \"armor\", \"im\", \"v\", \"cyberpunk\", \"2077\", \"und\", \"um\", \"jogo\", \"\", \"uma\", \"hist\", \"ria\", \"der\", \"algumas\", \"dx\", \"com\", \"vers\", \"ent\", \"gostei\", \"muito\", \"mais\", \"outros\", \"resistance\", \"glitchesbugs\", \"210\", \"wake\", \"geile\", \"viele\", \"denen\", \"spiel\", \"boa\", \"wave\", \"alguns\", \"fortnite\", \"iguana\", \"rias\", \"jogando\", \"e\", \"questsgigs\", \"ma\", \"principal\", \"tem\", \"samurai\", \"de\", \"em\", \"meme\", \"o\", \"por\", \"que\", \"build\", \"like\", \"n\", \"bug\", \"game\", \"got\", \"para\", \"please\", \"burn\", \"da\", \"100\", \"patch\", \"1010\", \"etc\", \"con\", \"dont\", \"see\", \"im\", \"panam\", \"feel\", \"2\", \"2077\", \"u\"], \"Freq\": [2713.0, 651.0, 621.0, 402.0, 469.0, 386.0, 283.0, 252.0, 301.0, 284.0, 291.0, 312.0, 145.0, 157.0, 236.0, 371.0, 158.0, 301.0, 250.0, 158.0, 121.0, 154.0, 190.0, 181.0, 507.0, 243.0, 228.0, 132.0, 96.0, 188.0, 96.84608254202863, 120.21293745743861, 51.70067617081591, 110.25157424611143, 32.77792778549625, 182.568691732969, 26.942932914778982, 27.900417058038467, 215.45479169262742, 38.53219002473078, 23.05744861465253, 86.53619658762447, 78.65385858833498, 46.90796759782084, 64.28049085901635, 26.853080803101964, 28.71484250972065, 47.932438468325564, 56.43153448268306, 28.666422755787952, 53.59060012990807, 21.978255456175702, 46.687751976085984, 20.068205561247673, 155.9936325215132, 27.679278674671306, 26.731638523668963, 68.74448722772806, 283.27804561200264, 29.611024281571414, 626.7045203752311, 2604.4481077221994, 290.6174897812602, 248.73881818806743, 330.8765993645512, 487.5984349954592, 169.67236259581222, 135.81590668903118, 114.0661843251628, 97.15951150677692, 98.05386217351358, 178.1538540484034, 332.6994861328714, 106.11881325802145, 396.1458365216591, 354.4509675111014, 359.30033941558025, 341.91049274655325, 367.43353160642727, 187.1117932844252, 583.7779952759525, 442.3340356281305, 277.4061673100253, 185.8933009671152, 176.111883483163, 160.80060064535752, 283.82925150580064, 239.68602193987462, 293.2684109330702, 374.49862720787974, 590.258723237446, 206.6559134929744, 255.1303843068393, 281.3328064184989, 228.457483526058, 263.39711740766165, 262.723530252379, 226.01039176793412, 231.5405166484965, 230.88959482580742, 218.5459566519506, 7.028914072420048, 6.416998388601416, 17.008284167739124, 3.9084437295037517, 2.652236244670833, 2.6494516341997496, 2.6500584511523204, 2.6485326874985033, 2.647353250161414, 2.0283515325263544, 2.0235054886710064, 2.0193449827269028, 2.0186679365808797, 2.0077328380475192, 1.3941235060815726, 1.393880802251261, 1.3929689702722272, 1.392881987055501, 1.3930293306574488, 1.3927410696542608, 1.3925994637315162, 1.3913252399339842, 1.3913076826356212, 1.3910131101853092, 1.3908863074749098, 1.3890275289201164, 1.389216987087419, 1.3885028755337407, 1.3883084829623231, 1.3883360238225004, 2.652510505736765, 2.6465038441321154, 2.0193658678792037, 2.557917749343452, 1.9885295142746242, 3.874435357328262, 7.0763522860466175, 5.108356319091447, 19.967231955859457, 7.084263398132521, 8.339783738504018, 2.0025625005635845, 14.579361151757839, 2.582330426818866, 10.970668472308134, 4.413128156193751, 42.05697925174132, 13.417212130630796, 15.338933485301885, 11.031708198747554, 12.521115163044966, 17.088354628560992, 10.453588822481047, 4.979824960701761, 38.769735230021936, 6.374750709089579, 18.151288618928316, 19.902360377740713, 9.365595403438482, 12.688510347259383, 10.652913043927574, 13.950638199001729, 6.493978764911404, 10.645296160031231, 9.442914532328649, 11.576248840257335, 9.715972062670271, 9.26493906766282, 10.641162276918632, 11.112043969855797, 10.505528130689243, 9.4426014845513, 10.398485069438488, 9.861111477775488, 9.63685726969655, 9.713161058874851, 9.444407246950254, 2.8049941888402192, 2.2667265452640484, 2.266502093571265, 2.266363994566105, 2.2641909757047713, 1.7276159427485802, 1.7275060838473124, 1.7268433392126208, 1.7255462532847243, 1.725775275630161, 1.7239191009402401, 1.724629021239815, 1.7222162063517912, 1.7225905101565566, 2.806390849700914, 1.1899655821369628, 1.189664408774646, 1.1891493941632045, 1.1877470199866933, 1.1876975589954837, 1.1877223711098859, 1.1875824764911838, 1.1876098187883046, 1.1876330801455568, 1.1874349913243256, 1.1878215379486974, 1.1869580926912586, 1.18669927948478, 1.1862826971429739, 1.1870141648050558, 11.44956063812336, 7.126835855787987, 3.345805890330594, 2.8059641466282335, 3.1737371417029, 7.136223323386964, 1.7268877398383933, 8.74658309002393, 2.8075504895740298, 5.831419522010647, 1.7270570172241506, 9.846191358244036, 2.7855676091640174, 3.3947285239528475, 2.2666181555011335, 5.507319113035832, 4.327433860468769, 5.877902406541742, 37.63176343244217, 3.186807575914663, 7.574618125554218, 12.049750014704642, 2.7860850723393797, 11.427596693274339, 2.5118060831835205, 4.562066355561732, 7.312349505669805, 8.829336062208082, 6.116489822080347, 5.969085621069246, 5.847740669684294, 5.702930640528985, 7.765009314767214, 6.5675139904783455, 6.839082582610949, 7.295778930951377, 6.869971053240231, 6.512476150081507, 5.374267740780862, 6.704043955877473, 7.486973249130552, 5.641472992005754, 6.7050142401406765, 5.684699612996744, 5.651215664610911, 6.109896329153139, 6.087582402900971, 16.88433808175705, 12.964330430823704, 8.735581556457852, 6.598110981424634, 5.516681906684008, 5.516572658393692, 5.514118583804433, 5.513947613316197, 4.447103493943826, 4.43435508257465, 4.433132365833875, 4.431227618806095, 3.8962588008400596, 3.894283381895663, 3.8925878731188286, 3.8898541969729967, 3.3549174745498793, 3.354125270139589, 3.352107262878628, 3.351432947866363, 3.3515823155853273, 2.8125379808907014, 2.811301068044405, 2.8115890020976972, 2.8111125067297627, 2.8110044928834044, 2.8102835776117105, 2.8101471715543096, 2.2794023122028597, 2.271984384151462, 4.440178880559295, 21.458373892943236, 6.6165887558156395, 4.9878970357274754, 4.987571142522463, 6.922175974934486, 5.531834089051138, 12.587312729275203, 16.373161010811852, 8.788513278949212, 7.704732588467872, 5.532628453738355, 6.075400500576298, 7.425508771746159, 21.272839434886702, 5.520753720080723, 6.1990961057597875, 5.538255666522629, 5.727602087522641, 5.2173391223286245, 4.338781915011771, 4.323410068921257, 4.318620935844817, 4.308621596955813, 2.9139338810934863, 2.445961426008055, 2.4451691716515436, 1.9806145685196022, 1.9725665726053772, 1.5053452789865263, 1.5032594784197557, 1.5032597889453723, 1.5021431388280422, 1.502052568856531, 1.5026756902605285, 1.5029054792168202, 1.5008598399631312, 1.4987325324722736, 1.4978307660816377, 1.4888558512018313, 3.7858397144020635, 1.0373207591060438, 1.0373193099864995, 1.0373159977132558, 1.037314962627867, 1.035235786607584, 1.0348030174065683, 1.0348413155659504, 1.0327499255380808, 1.0331975999686938, 1.0338064371943274, 1.0343502710575507, 9.049313505272899, 1.3537741027202361, 1.9751776790069133, 1.5034580077973085, 1.503126883981463, 3.6242711659090086, 9.509683051161247, 5.733535876338975, 2.3694684087660027, 1.973551352844187, 1.9729903365635113, 3.403020007937632, 4.860089835972012, 9.303364035007265, 3.412837171798224, 7.745393255214039, 11.558278508720383, 4.745304662843291, 1.9756840427790658, 2.5931288314881185, 1.9042051861769567, 1.9863489415730036, 2.804287285868431, 3.4138219520370336, 2.6725360281335186, 2.883300943049047, 2.6286587585065, 3.353813704695427, 3.0496377158936903, 3.176744338472425, 2.44718758815951, 3.0332429984220615, 2.531477075566333, 2.5144871839962013, 2.5116431833822075], \"Total\": [2713.0, 651.0, 621.0, 402.0, 469.0, 386.0, 283.0, 252.0, 301.0, 284.0, 291.0, 312.0, 145.0, 157.0, 236.0, 371.0, 158.0, 301.0, 250.0, 158.0, 121.0, 154.0, 190.0, 181.0, 507.0, 243.0, 228.0, 132.0, 96.0, 188.0, 97.91635280362784, 121.6288336736538, 52.35174154316324, 112.31014703615996, 33.3910836879829, 186.11982166487758, 27.489187977376865, 28.466719105310027, 219.88068914876374, 39.325174099516346, 23.544306027190352, 88.37474427234902, 80.35217695809257, 47.95192235919693, 65.72034389496842, 27.458447979685257, 29.371325859054004, 49.057216877792, 57.76162102876826, 29.34220413055952, 54.85475192363503, 22.50916733222185, 47.81675239904492, 20.5545699148024, 159.79563637293322, 28.355730703960692, 27.38761243716099, 70.44607264830341, 290.3072428727134, 30.359578921265165, 642.8840094393075, 2713.680724328271, 298.7406248750326, 255.5171438491016, 342.33850951224747, 507.2150219541849, 174.87320522543072, 139.79626373186105, 117.3874515717586, 99.83280726612706, 100.78869238069814, 184.2715071531701, 346.8534606995523, 109.39810511818837, 414.35657823649166, 371.1510838200533, 377.23344559231845, 358.96676782940807, 386.4910392866806, 194.28123153754035, 621.3107609552119, 469.42744894202707, 291.8692329022975, 193.86431464898828, 183.4606618427715, 167.21428040544313, 301.3568923455906, 252.7845810685466, 312.049077396643, 402.8553803906525, 651.6481001040298, 216.77395518436634, 271.22381266458854, 301.5770295917291, 241.3862820597689, 284.12492156204945, 283.90588075616705, 243.2506249000953, 250.6505009309569, 252.028229736084, 236.40277761737906, 7.607838452425206, 6.9828728237860815, 18.833472788327494, 4.445985990386001, 3.1751268270811455, 3.1760258483373285, 3.1767929890845066, 3.176679495452596, 3.1779766393912925, 2.539297196130741, 2.5387015010102427, 2.541513468585969, 2.541345676672471, 2.5464962427287876, 1.9051741171578926, 1.904925042518721, 1.9049223724773983, 1.9052849903679496, 1.905599775540076, 1.9057018905391048, 1.9057948033723888, 1.9045833019324003, 1.9048154642863517, 1.9048014118732537, 1.9047523152283528, 1.9054593110627196, 1.9059155295783377, 1.9059400940556268, 1.9057179644432984, 1.9059694091921173, 3.6500999640925667, 3.7850587852677178, 3.029139707580316, 4.217528368578179, 3.0397523041874734, 7.436434432059515, 16.83266513758331, 11.052131707302296, 74.59950980587465, 20.25438714490435, 26.152924624714522, 3.231797870296956, 72.71894336572487, 5.1986590738125145, 56.27508153568384, 12.768291968316607, 651.6481001040298, 96.37300273913719, 145.49603817956404, 81.83707199024626, 110.57865076829593, 252.028229736084, 88.01506270720434, 17.766620475414097, 2713.680724328271, 37.036121456618964, 469.42744894202707, 621.3107609552119, 102.61872104851497, 236.40277761737906, 158.98998438242302, 402.8553803906525, 42.715062235602815, 190.583098285274, 132.98292057497636, 284.12492156204945, 158.86104623880743, 143.85985088632, 250.6505009309569, 301.3568923455906, 371.1510838200533, 184.3081476575415, 414.35657823649166, 312.049077396643, 243.2506249000953, 377.23344559231845, 229.72503554355367, 3.3461430835310844, 2.8019936660139813, 2.8017745324366525, 2.801701680129239, 2.8026781406895718, 2.260699974546809, 2.2605904230052647, 2.26060783224017, 2.2616377270160597, 2.262486582656598, 2.26293121951466, 2.2662520572990443, 2.26309772601366, 2.2642459914870274, 3.814597655435837, 1.7194303414767047, 1.7193940189534764, 1.7192668082064577, 1.7194433323046088, 1.7194929033078663, 1.7195327183687734, 1.7193792481599144, 1.7194429113439442, 1.7195219977395917, 1.7194807959852483, 1.7201664324151262, 1.7194717453970096, 1.7194545427922259, 1.7194948236635772, 1.7214316702412, 20.69772650058842, 13.109312840935514, 6.058360832602519, 4.889815654984418, 5.991050534976909, 17.90217506979951, 2.803652982173987, 25.106648178558135, 5.517225906670079, 15.297350492689954, 2.8986657075168862, 36.13537427542416, 5.868202985887933, 8.810189230414144, 4.755368097415665, 21.63499713226522, 18.423636128948772, 39.3447800295047, 2713.680724328271, 11.114647232118157, 111.27032504331719, 402.8553803906525, 8.101839529574535, 386.4910392866806, 6.506751880188111, 36.25546199019055, 157.51583616450438, 291.8692329022975, 96.01291267218204, 96.37300273913719, 90.7685830291271, 87.5812903006743, 301.5770295917291, 158.86104623880743, 188.2189962905944, 283.90588075616705, 228.1469233927406, 181.45687782040036, 86.32336757549537, 312.049077396643, 642.8840094393075, 133.45632170001792, 507.2150219541849, 158.98998438242302, 154.02866800386028, 621.3107609552119, 651.6481001040298, 17.485027245537484, 13.700211700962765, 9.338874213886939, 7.160062915269194, 6.071457778363822, 6.072286607863951, 6.071728535278236, 6.072523926293058, 4.9852826634248855, 4.9854730130896305, 4.985369388401598, 4.98485026963763, 4.441557145115556, 4.441701901841229, 4.440919337725708, 4.441727209724771, 3.898350584890839, 3.8976021625545707, 3.8984132790934045, 3.8982702514998793, 3.898536952000894, 3.3539683777340583, 3.3544389017534595, 3.354855464858406, 3.3543237728868767, 3.3550619938999557, 3.3543398105854854, 3.35452887053045, 2.8106793275326476, 2.8110340184399907, 5.526238249060379, 29.700357685010644, 8.783980031247454, 6.612691788741789, 6.613159201445082, 9.957104981923763, 8.238400715937658, 25.106648178558135, 36.13537427542416, 20.69772650058842, 17.90217506979951, 13.109312840935514, 21.63499713226522, 40.765951622709224, 2713.680724328271, 32.63717608223988, 283.90588075616705, 131.1574462873139, 301.5770295917291, 154.49764446497483, 4.882107079476133, 4.8891680795435, 4.890706742787163, 4.910986519367957, 3.475072359701941, 2.9992083414874764, 3.000255248183074, 2.523930486181423, 2.527441547924574, 2.0528127871157738, 2.0552090182943363, 2.0552370559017183, 2.0542528107283697, 2.0543855630965924, 2.055390717714391, 2.0570081049665734, 2.0547556304687125, 2.0581910259295233, 2.0581206783994035, 2.0656626662919555, 5.491913297724879, 1.580634615190192, 1.5806330901668848, 1.5806302880417147, 1.5806299604799756, 1.5811876391333488, 1.581853553834796, 1.5833591135761556, 1.5811096047945983, 1.581802897802068, 1.582827149642424, 1.5839014168144678, 21.63499713226522, 2.2128168267881745, 3.6116834874926544, 2.5985108141569437, 2.59997230679967, 8.9102903891838, 36.13537427542416, 18.039897366413673, 5.469980467909054, 4.696327683575783, 5.239282514452846, 25.106648178558135, 68.12173693665719, 651.6481001040298, 29.700357685010644, 621.3107609552119, 2713.680724328271, 121.68174628988199, 5.785447450512313, 18.68280245035365, 5.547416250857555, 6.870658691947959, 44.80322792749652, 132.6380207120752, 39.3447800295047, 62.61464864037363, 38.42610183929983, 284.12492156204945, 157.51583616450438, 283.90588075616705, 25.22977623651088, 371.1510838200533, 81.83707199024626, 154.49764446497483, 74.59950980587465], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.4606, -6.2444, -7.0882, -6.3309, -7.5439, -5.8266, -7.74, -7.705, -5.6609, -7.3822, -7.8957, -6.5731, -6.6686, -7.1855, -6.8704, -7.7433, -7.6763, -7.1639, -7.0007, -7.678, -7.0523, -7.9436, -7.1902, -8.0346, -5.9839, -7.713, -7.7478, -6.8033, -5.3873, -7.6455, -4.5932, -3.1687, -5.3617, -5.5173, -5.2319, -4.8442, -5.8998, -6.1224, -6.2969, -6.4573, -6.4482, -5.851, -5.2264, -6.3691, -5.0519, -5.1631, -5.1495, -5.1991, -5.1271, -5.802, -4.6642, -4.9416, -5.4082, -5.8085, -5.8626, -5.9535, -5.3853, -5.5544, -5.3526, -5.1081, -4.6531, -5.7026, -5.4919, -5.3941, -5.6023, -5.46, -5.4626, -5.6131, -5.5889, -5.5917, -5.6467, -6.3296, -6.4207, -5.446, -6.9165, -7.3043, -7.3053, -7.3051, -7.3057, -7.3061, -7.5724, -7.5748, -7.5769, -7.5772, -7.5827, -7.9474, -7.9476, -7.9482, -7.9483, -7.9482, -7.9484, -7.9485, -7.9494, -7.9494, -7.9496, -7.9497, -7.9511, -7.9509, -7.9514, -7.9516, -7.9516, -7.3042, -7.3064, -7.5769, -7.3405, -7.5923, -6.9253, -6.3229, -6.6488, -5.2856, -6.3218, -6.1586, -7.5852, -5.6001, -7.331, -5.8844, -6.7951, -4.5406, -5.6831, -5.5493, -5.8789, -5.7523, -5.4413, -5.9327, -6.6743, -4.622, -6.4273, -5.3809, -5.2888, -6.0426, -5.739, -5.9138, -5.6441, -6.4088, -5.9146, -6.0344, -5.8307, -6.0059, -6.0534, -5.9149, -5.8716, -5.9278, -6.0344, -5.938, -5.9911, -6.0141, -6.0062, -6.0342, -6.9075, -7.1206, -7.1207, -7.1208, -7.1217, -7.3922, -7.3923, -7.3926, -7.3934, -7.3933, -7.3943, -7.3939, -7.3953, -7.3951, -6.907, -7.765, -7.7653, -7.7657, -7.7669, -7.7669, -7.7669, -7.767, -7.767, -7.767, -7.7671, -7.7668, -7.7676, -7.7678, -7.7681, -7.7675, -5.501, -5.9751, -6.7312, -6.9072, -6.784, -5.9738, -7.3926, -5.7703, -6.9066, -6.1757, -7.3925, -5.6519, -6.9145, -6.7167, -7.1207, -6.2329, -6.474, -6.1677, -4.3111, -6.7799, -5.9141, -5.4499, -6.9143, -5.5029, -7.0179, -6.4212, -5.9494, -5.7609, -6.128, -6.1524, -6.1729, -6.198, -5.8893, -6.0568, -6.0163, -5.9516, -6.0118, -6.0652, -6.2573, -6.0362, -5.9258, -6.2088, -6.0361, -6.2012, -6.2071, -6.129, -6.1327, -5.0563, -5.3205, -5.7153, -5.9959, -6.1749, -6.1749, -6.1754, -6.1754, -6.3904, -6.3933, -6.3936, -6.394, -6.5227, -6.5232, -6.5236, -6.5243, -6.6722, -6.6725, -6.6731, -6.6733, -6.6732, -6.8486, -6.849, -6.8489, -6.8491, -6.8491, -6.8494, -6.8494, -7.0588, -7.062, -6.392, -4.8166, -5.9931, -6.2757, -6.2757, -5.9479, -6.1722, -5.35, -5.087, -5.7092, -5.8408, -6.172, -6.0784, -5.8778, -4.8252, -6.1742, -6.0583, -6.171, -6.1374, -6.2307, -6.0158, -6.0193, -6.0205, -6.0228, -6.4139, -6.589, -6.5893, -6.8, -6.8041, -7.0744, -7.0758, -7.0758, -7.0765, -7.0766, -7.0761, -7.076, -7.0774, -7.0788, -7.0794, -7.0854, -6.1521, -7.4468, -7.4468, -7.4468, -7.4468, -7.4488, -7.4492, -7.4491, -7.4512, -7.4507, -7.4501, -7.4496, -5.2807, -7.1805, -6.8027, -7.0756, -7.0758, -6.1957, -5.2311, -5.7371, -6.6207, -6.8036, -6.8038, -6.2587, -5.9023, -5.253, -6.2558, -5.4363, -5.036, -5.9262, -6.8025, -6.5305, -6.8393, -6.7971, -6.4522, -6.2556, -6.5004, -6.4245, -6.5169, -6.2733, -6.3684, -6.3275, -6.5885, -6.3738, -6.5546, -6.5613, -6.5625], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.1549, 0.1542, 0.1534, 0.1474, 0.1474, 0.1467, 0.1459, 0.1458, 0.1456, 0.1456, 0.145, 0.1449, 0.1446, 0.1439, 0.1438, 0.1436, 0.1433, 0.1427, 0.1426, 0.1426, 0.1426, 0.1421, 0.142, 0.142, 0.1418, 0.1418, 0.1417, 0.1415, 0.1414, 0.141, 0.1404, 0.1248, 0.1384, 0.139, 0.1319, 0.1265, 0.1357, 0.137, 0.1372, 0.1388, 0.1384, 0.1322, 0.1243, 0.1355, 0.121, 0.1199, 0.1172, 0.1172, 0.1154, 0.1283, 0.1036, 0.1065, 0.1151, 0.1239, 0.125, 0.1268, 0.106, 0.1127, 0.1039, 0.0929, 0.067, 0.1181, 0.1048, 0.0964, 0.1109, 0.0902, 0.0884, 0.0924, 0.0866, 0.0783, 0.0874, 2.8408, 2.8354, 2.818, 2.7911, 2.74, 2.7387, 2.7386, 2.7381, 2.7373, 2.6953, 2.6931, 2.69, 2.6897, 2.6822, 2.6076, 2.6076, 2.6069, 2.6067, 2.6066, 2.6064, 2.6062, 2.6059, 2.6058, 2.6056, 2.6055, 2.6038, 2.6037, 2.6032, 2.6032, 2.6031, 2.6007, 2.5621, 2.5144, 2.4199, 2.4956, 2.2679, 2.0534, 2.1482, 1.6019, 1.8694, 1.777, 2.4413, 1.3129, 2.2202, 1.2849, 1.8576, 0.1795, 0.9483, 0.6702, 0.916, 0.7416, 0.2288, 0.7894, 1.648, -1.3285, 1.1604, -0.3328, -0.5211, 0.526, -0.0049, 0.2169, -0.4431, 1.0363, 0.035, 0.275, -0.2805, 0.1257, 0.1773, -0.2394, -0.3803, -0.6448, -0.0514, -0.7651, -0.5346, -0.3086, -0.7394, -0.2715, 3.0843, 3.0487, 3.0487, 3.0486, 3.0473, 2.9917, 2.9917, 2.9913, 2.9901, 2.9899, 2.9886, 2.9876, 2.9875, 2.9873, 2.9537, 2.8926, 2.8924, 2.892, 2.8907, 2.8907, 2.8907, 2.8906, 2.8906, 2.8906, 2.8904, 2.8904, 2.89, 2.8898, 2.8895, 2.889, 2.6686, 2.6512, 2.6669, 2.7053, 2.6253, 2.3409, 2.7761, 2.2062, 2.5851, 2.2962, 2.7428, 1.9605, 2.5156, 2.307, 2.5197, 1.8924, 1.812, 1.3595, -1.0175, 2.0114, 0.5735, -0.2489, 2.1932, -0.2604, 2.3088, 1.1879, 0.1907, -0.2376, 0.5072, 0.479, 0.5184, 0.5291, -0.3987, 0.0748, -0.0543, -0.4007, -0.2422, -0.0666, 0.4842, -0.5798, -1.1921, 0.097, -1.0654, -0.0704, -0.0446, -1.3613, -1.4126, 3.282, 3.2617, 3.2502, 3.2352, 3.2211, 3.221, 3.2206, 3.2204, 3.2027, 3.1998, 3.1995, 3.1992, 3.186, 3.1854, 3.1852, 3.1843, 3.1668, 3.1668, 3.166, 3.1658, 3.1658, 3.1409, 3.1403, 3.1403, 3.1403, 3.14, 3.14, 3.1399, 3.1074, 3.104, 3.0981, 2.9919, 3.0336, 3.035, 3.0348, 2.9534, 2.9187, 2.6265, 2.5253, 2.4604, 2.4739, 2.4543, 2.0469, 1.614, -1.5317, 1.54, -0.5073, 0.1522, -0.6468, -0.0713, 3.5982, 3.5932, 3.5918, 3.5854, 3.5401, 3.5123, 3.5116, 3.4738, 3.4683, 3.406, 3.4035, 3.4035, 3.4032, 3.4031, 3.403, 3.4024, 3.4021, 3.399, 3.3984, 3.3888, 3.3442, 3.295, 3.295, 3.295, 3.295, 3.2927, 3.2918, 3.2909, 3.2903, 3.2903, 3.2903, 3.2901, 2.8446, 3.2248, 3.1127, 3.169, 3.1683, 2.8167, 2.3813, 2.57, 2.8796, 2.8493, 2.7396, 1.7177, 1.076, -0.5329, 1.5526, -0.6685, -1.7424, 0.472, 2.6418, 1.7415, 2.647, 2.4753, 0.9451, 0.0564, 1.0269, 0.6382, 1.034, -0.7231, -0.2283, -0.7766, 1.3831, -1.0908, 0.2403, -0.4019, 0.325]}, \"token.table\": {\"Topic\": [5, 2, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 1, 3, 3, 2, 3, 5, 5, 1, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 3, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 5, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 5, 4, 2, 5, 2, 5, 1, 1, 4, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 3, 1, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 1, 2, 3, 4, 2, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 3, 1, 3, 1, 2, 4, 3, 2, 1, 2, 3, 4, 5, 3, 4, 5, 4, 2, 3, 3, 4, 5, 1, 2, 3, 3, 4, 5, 5, 2, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 4, 5, 5, 2, 3, 4, 5, 3, 4, 1, 5, 3, 4, 1, 2, 3, 2, 1, 1, 3, 5, 3, 3, 3, 5, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 3, 1, 3, 2, 1, 2, 3, 4, 5, 1, 3, 2, 5, 1, 2, 3, 4, 5, 1, 5, 2, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 3, 4, 1, 2, 3, 4, 4, 5, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 4, 3, 1, 1, 2, 3, 4, 5, 4, 5, 5, 3, 4, 2, 4, 5, 4, 1, 2, 3, 4, 4, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 5, 2, 3, 3, 4, 1, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 1, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 4, 1, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 4, 1, 2, 3, 4, 5, 5, 1, 4, 4, 4, 1, 2, 1, 2, 5, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 2, 1, 2, 3, 4, 5, 1, 1, 3, 5, 2, 2, 3, 4, 5, 3, 4, 5, 1, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 5, 1, 2, 4, 5, 5, 5, 3, 1, 2, 3, 4, 4, 1, 2, 5, 1, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 1, 3, 4, 1, 2, 3, 4, 5, 2, 3, 1, 1, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 2, 4, 5, 2, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 3, 1, 1, 3, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 5, 5, 4, 3, 5, 1, 5, 1, 2, 1, 2, 3, 4, 5, 3, 4, 4, 2, 5, 3, 5, 5, 2, 4, 3, 2, 1, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 3, 2, 3, 4, 4, 4, 2, 4], \"Freq\": [0.81450030135998, 0.5249891110782842, 0.8704729950063491, 0.044639640769556364, 0.022319820384778182, 0.06695946115433454, 0.6354083052758833, 0.10166532884414134, 0.152497993266212, 0.05083266442207067, 0.076248996633106, 0.8064804665526915, 0.13441341109211524, 0.012219401008374113, 0.012219401008374113, 0.03665820302512234, 0.8737997298761729, 0.045308134141727484, 0.032362952958376774, 0.032362952958376774, 0.019417771775026064, 0.48410614972050936, 0.5247691634076651, 0.9223683388966226, 0.048831265000409435, 0.005425696111156604, 0.010851392222313207, 0.005425696111156604, 0.5675247000074893, 0.34051482000449357, 0.581643288422, 0.9443823351693138, 0.8847178053072928, 0.7913140470616674, 0.6315686640040946, 0.9730196293524476, 0.9165639906366676, 0.0674527612156855, 0.007935618966551235, 0.0039678094832756175, 0.0039678094832756175, 0.9882305401812282, 0.9762469335265519, 0.0062579931636317435, 0.012515986327263487, 0.0062579931636317435, 0.581583574876921, 0.7695562353030405, 0.6740779271026363, 0.09191971733217767, 0.18383943466435534, 0.03063990577739256, 0.9594339233436155, 0.02063298759878743, 0.005158246899696858, 0.005158246899696858, 0.005158246899696858, 0.9829191160405691, 0.020913172681714238, 0.7695720938910623, 0.8942263031670179, 0.903579206774851, 0.023168697609611565, 0.057921744024028915, 0.011584348804805782, 0.9721329221412244, 0.017155286861315726, 0.011436857907543816, 0.005718428953771908, 0.778226244574015, 0.13489254905949594, 0.0622580995659212, 0.010376349927653534, 0.9722604238056722, 0.7853928729369849, 0.6324360090166791, 0.8218952986252844, 0.27396509954176146, 0.9858471621777788, 0.9773795571952154, 0.9488904466407947, 0.9399483104109612, 0.03219001063051237, 0.00965700318915371, 0.006438002126102474, 0.012876004252204948, 0.8514169281081477, 0.07339801104380583, 0.07339801104380583, 0.3605282007981332, 0.1802641003990666, 0.1802641003990666, 0.3605282007981332, 0.5815879689206638, 0.6265520885527442, 0.3132760442763721, 0.9106084789669215, 0.06256088786795644, 0.006951209763106272, 0.006951209763106272, 0.013902419526212543, 0.9201036593736502, 0.9659659420489947, 0.005426774955331431, 0.010853549910662862, 0.010853549910662862, 0.005426774955331431, 0.9415725497010417, 0.038344583471988124, 0.010651273186663368, 0.004260509274665347, 0.004260509274665347, 0.9689381720595871, 0.01828185230301108, 0.00914092615150554, 0.9784493099063147, 0.020384360623048225, 0.938954867113964, 0.032046241198428804, 0.022432368838900166, 0.006409248239685762, 0.5246673924445984, 0.7869326779970783, 0.5816002550762962, 0.9731370299551548, 0.7546953401955698, 0.0520479544962462, 0.0780719317443693, 0.0520479544962462, 0.0780719317443693, 0.9723312971442797, 0.00992174793004367, 0.00992174793004367, 0.9874547156737172, 0.8965546078305145, 0.20450668707329553, 0.6135200612198866, 0.3094252920923283, 0.6188505841846565, 0.7115717472315486, 0.7136031679713031, 0.5248558641124231, 0.9317685779331867, 0.01989541447544171, 0.026527219300588944, 0.01989541447544171, 0.003315902412573618, 0.14554645265263227, 0.5821858106105291, 0.29109290530526455, 0.8023477677112456, 0.5247366182498687, 0.8837444256209411, 0.2767371364076626, 0.44277941825226025, 0.2767371364076626, 0.9716244855403537, 0.010016747273611895, 0.010016747273611895, 0.49518344695742983, 0.3301222979716199, 0.6326590142967126, 0.7924148509438138, 0.7878043161845244, 0.34498631470568586, 0.6899726294113717, 0.8274615286413105, 0.02758205095471035, 0.13791025477355176, 0.9844441499246391, 0.011315449999133783, 0.9174110440085865, 0.06767786390227278, 0.007519762655808086, 0.8825143670839651, 0.384714591128837, 0.5770718866932555, 0.8846817457061855, 0.9256491776718854, 0.04223494346791872, 0.014078314489306241, 0.0070391572446531206, 0.01055873586697968, 0.9742729646623176, 0.046221406635116036, 0.2773284398106962, 0.2773284398106962, 0.4159926597160443, 0.5314593368352452, 0.4348303665015642, 0.6651922544937182, 0.3325961272468591, 0.22768722070011022, 0.7969052724503857, 0.9794306472111004, 0.008903914974646368, 0.5815837172624614, 0.9448441474565797, 0.9801484004735765, 0.9844179055840968, 0.01822996121452031, 0.9735900029222141, 0.581566158989294, 0.7137774878860202, 0.7864525360164714, 0.26215084533882377, 0.5815739646068505, 0.9103301102491003, 0.03194140737716141, 0.015970703688580706, 0.04791211106574211, 0.9527344329615738, 0.025071958762146677, 0.013928865978970377, 0.005571546391588151, 0.0027857731957940755, 0.9291429466992671, 0.022479264839498397, 0.04495852967899679, 0.0074930882798327995, 0.30737302371858377, 0.15368651185929189, 0.4610595355778757, 0.15368651185929189, 0.983237563645988, 0.010745765722906973, 0.0053728828614534865, 0.17994273306493894, 0.08997136653246947, 0.2699140995974084, 0.2699140995974084, 0.08997136653246947, 0.580911817347873, 0.3338312685435741, 0.5007469028153612, 0.5249852380711613, 0.9537894820526275, 0.029637526278471476, 0.005388641141540269, 0.0026943205707701343, 0.008082961712310403, 0.9738232669975403, 0.015215988546836567, 0.6602534689948668, 0.3301267344974334, 0.9625222082446321, 0.01544153275258768, 0.010294355168391786, 0.010294355168391786, 0.005147177584195893, 0.9906414732841857, 0.6324672223655929, 0.786984635092505, 0.9593337243644886, 0.021803039190102014, 0.01635227939257651, 0.0054507597975255034, 0.9637135905114739, 0.9595823033472662, 0.014371624358887627, 0.014003121170198201, 0.007738566962477953, 0.004422038264273116, 0.6326572823281322, 0.5249557748116924, 0.9516653525678537, 0.026508784194090633, 0.010603513677636253, 0.005301756838818126, 0.005301756838818126, 0.4858801578038165, 0.581339096703563, 0.8868483165634433, 0.06918674810069417, 0.03773822623674227, 0.0062897043727903786, 0.0062897043727903786, 0.9621166150005697, 0.015772403524599504, 0.013800853084024563, 0.005914651321724813, 0.003943100881149876, 0.9735270904967729, 0.903997545679098, 0.04109079753086809, 0.016436319012347236, 0.04109079753086809, 0.9728443119256567, 0.014306533998906716, 0.007153266999453358, 0.9490551547539273, 0.01027857568325553, 0.030835727049766594, 0.00342619189441851, 0.00342619189441851, 0.8672881428518636, 0.08770329534457048, 0.029234431781523493, 0.009744810593841165, 0.009744810593841165, 0.7695194471506223, 0.9695018768969298, 0.017312533516016606, 0.9007144007367826, 0.8521268711640763, 0.11361691615521016, 0.011361691615521016, 0.011361691615521016, 0.8943133643460375, 0.6668426372167554, 0.9822043496599661, 0.9744942990872254, 0.011740895169725608, 0.003913631723241869, 0.007827263446483738, 0.003913631723241869, 0.6321900164612865, 0.9263633402010362, 0.017611470346027305, 0.024656058484438227, 0.021133764415232764, 0.010566882207616382, 0.45240141290538827, 0.45240141290538827, 0.09048028258107765, 0.8832962529334166, 0.9833039369149912, 0.9628364252719599, 0.011960700935055402, 0.011960700935055402, 0.005980350467527701, 0.011960700935055402, 0.8943680464745566, 0.6313524247053163, 0.8178777036466598, 0.533971542592347, 0.45768989365058316, 0.20086159617989585, 0.7030155866296355, 0.10043079808994793, 0.900550576641076, 0.4575955818849182, 0.06537079741213117, 0.392224784472787, 0.06537079741213117, 0.8023310906503319, 0.9880570373746835, 0.11171826843398187, 0.05585913421699094, 0.39101393951893654, 0.4468730737359275, 0.9883374769994487, 0.9053966395448889, 0.0644519641709921, 0.00920742345299887, 0.006138282301999247, 0.013811135179498306, 0.5250026431284921, 0.5815709034581036, 0.24276556445365488, 0.7282966933609646, 0.9836047454719512, 0.9129875711200182, 0.05771760507080575, 0.020988220025747545, 0.005247055006436886, 0.010494110012873772, 0.15121365893951016, 0.7560682946975508, 0.9668792461344702, 0.020447597350275806, 0.00876325600726106, 0.005842170671507373, 0.6500229035163048, 0.3058931310664964, 0.03823664138331205, 0.2768791904005497, 0.2768791904005497, 0.5537583808010994, 0.97780301140742, 0.0045479209832903255, 0.009095841966580651, 0.0045479209832903255, 0.0045479209832903255, 0.9722859113540052, 0.9263850543856736, 0.054990893639332225, 0.012690206224461282, 0.004230068741487094, 0.008460137482974188, 0.9297680013648284, 0.0265648000389951, 0.03719072005459314, 0.0053129600077990195, 0.0053129600077990195, 0.3656320185663326, 0.1828160092831663, 0.3656320185663326, 0.7563366222662077, 0.20627362425442028, 0.013751574950294686, 0.02750314990058937, 0.9549117643028029, 0.03229170217449092, 0.00461310031064156, 0.00461310031064156, 0.00461310031064156, 0.9255916071913446, 0.04388580896165858, 0.015958475986057666, 0.007979237993028833, 0.007979237993028833, 0.9730510032778653, 0.15122434735314833, 0.7561217367657416, 0.13467851271093426, 0.7070621917324048, 0.1010088845332007, 0.9880956528352374, 0.9089217079803048, 0.045446085399015235, 0.0389537874848702, 0.006492297914145034, 0.006492297914145034, 0.909306949297955, 0.038576658455064756, 0.038576658455064756, 0.01653285362359918, 0.21293233082888294, 0.21293233082888294, 0.4258646616577659, 0.7113779721959234, 0.04906054980661541, 0.024530274903307704, 0.1717119243231539, 0.024530274903307704, 0.8943373505571426, 0.8944628160229705, 0.7697040064329543, 0.960059615171168, 0.0230644952593674, 0.008649185722262774, 0.002883061907420925, 0.00576612381484185, 0.9733517554804207, 0.9866081616960648, 0.8024313236374855, 0.9881864719640419, 0.7695438593154148, 0.23710569618222196, 0.7113170885466659, 0.7927141252666883, 0.07927141252666882, 0.07927141252666882, 0.17284747784053384, 0.3456949556810677, 0.3456949556810677, 0.5815533425549735, 0.9273359127320139, 0.0075393163636749095, 0.03769658181837455, 0.0075393163636749095, 0.022617949091024728, 0.8897250903280781, 0.017974244249052085, 0.07189697699620834, 0.008987122124526042, 0.017974244249052085, 0.9336089079462793, 0.02629884247735998, 0.030681982890253312, 0.00438314041289333, 0.00438314041289333, 0.8681603486115623, 0.11756338054114907, 0.009043336964703774, 0.009043336964703774, 0.8427940430341726, 0.14046567383902878, 0.8592452062941665, 0.9401829341413622, 0.02580894329015504, 0.018434959492967886, 0.011060975695780732, 0.007373983797187155, 0.9932811873531803, 0.6958270866774552, 0.10705032102730079, 0.1605754815409512, 0.5247410442129066, 0.7876195047383598, 0.1908658289071921, 0.3817316578143842, 0.3817316578143842, 0.7138518758741446, 0.3848358046277511, 0.7696716092555022, 0.781873589505148, 0.195468397376287, 0.017769854306935184, 0.35847078972836693, 0.5177911407187522, 0.11949026324278898, 0.9740891454643283, 0.020084312277615018, 0.003347385379602503, 0.003347385379602503, 0.003347385379602503, 0.451912687889067, 0.451912687889067, 0.9873575384088581, 0.9283728558802636, 0.03475192508642698, 0.029787364359794555, 0.004964560726632426, 0.002482280363316213, 0.9711429839697315, 0.01703759620999529, 0.008518798104997645, 0.1704099197667218, 0.3408198395334436, 0.5112297593001655, 0.4034191422527143, 0.5378921896702857, 0.8839831428532107, 0.8838094515435375, 0.4858635507597642, 0.5430922160864989, 0.34560413750959024, 0.04937201964422718, 0.04937201964422718, 0.6666099496738422, 0.631780924547516, 0.5816052514709616, 0.5065679211448474, 0.28142662285824854, 0.05628532457164971, 0.16885597371494915, 0.9005557077889154, 0.44891915137306854, 0.11222978784326713, 0.44891915137306854, 0.979472629290169, 0.014195255496958971, 0.9445766952968978, 0.3702862774619215, 0.49371503661589533, 0.12342875915397383, 0.9078452267532992, 0.01904570405776152, 0.04443997613477688, 0.0063485680192538405, 0.01904570405776152, 0.8728760012232282, 0.10309559069565688, 0.0068730393797104584, 0.0068730393797104584, 0.5346746891497982, 0.4158580915609541, 0.05940829879442202, 0.9917311466010689, 0.5437515249055026, 0.3625010166036684, 0.9748292781109933, 0.013778505697681884, 0.003444626424420471, 0.006889252848840942, 0.003444626424420471, 0.5248864085408548, 0.5815569683403622, 0.9881559977429957, 0.9882877809047076, 0.632659145405759, 0.5250492320211958, 0.9290829164069764, 0.04110986355783081, 0.020554931778915406, 0.0041109863557830814, 0.0041109863557830814, 0.9752925734563521, 0.007777452738886381, 0.010888433834440932, 0.003110981095554552, 0.003110981095554552, 0.9439968698368463, 0.7114819624665797, 0.9443485963070402, 0.384619481286287, 0.769238962572574, 0.5248078477426403, 0.879183210656662, 0.03425389132428553, 0.06850778264857106, 0.011417963774761845, 0.8957128536828245, 0.031245797221493878, 0.062491594442987755, 0.01041526574049796, 0.9424041965309158, 0.03650157099239462, 0.016591623178361194, 0.0033183246356722385, 0.0033183246356722385, 0.5246822246215911, 0.9556985958455938, 0.024133802925393782, 0.007240140877618134, 0.009653521170157513, 0.0024133802925393783, 0.5249550390065663, 0.5815668084911864, 0.9768816279162463, 0.7056153252817072, 0.21711240777898683, 0.7138333141534541, 0.7560186892895054, 0.16200400484775118, 0.027000667474625196, 0.027000667474625196, 0.6568407772049635, 0.2680982764101892, 0.01340491382050946, 0.02680982764101892, 0.040214741461528376, 0.8181350967941111, 0.8632913762570722, 0.8023617255138755, 0.8847246186866387, 0.8193183670254963, 0.9831718690235637, 0.012445213531943843, 0.05309695196627647, 0.9026481834267001, 0.9149308971533926, 0.015248848285889877, 0.015248848285889877, 0.04574654485766963, 0.015248848285889877, 0.7133550452628326, 0.3566775226314163, 0.8943637703409552, 0.657948345740164, 0.328974172870082, 0.5815797830724259, 0.9731237543897419, 0.6326578927272862, 0.792590068000175, 0.26419668933339163, 0.8843149263515085, 0.8996879451823733, 0.18208590445414852, 0.7283436178165941, 0.8938629284018367, 0.06294809354942513, 0.044063665484597586, 0.6321697717059571, 0.9315484465750693, 0.0391772711176431, 0.017412120496730268, 0.008706060248365134, 0.004353030124182567, 0.9494249965147998, 0.023735624912869995, 0.019779687427391664, 0.0039559374854783325, 0.0039559374854783325, 0.8703451939384067, 0.055085138856861185, 0.06610216662823343, 0.011017027771372237, 0.9495692336809314, 0.012936910540612143, 0.028461203189346716, 0.005174764216244857, 0.9445441474737394, 0.02071368744459955, 0.016570949955679638, 0.008285474977839819, 0.008285474977839819, 0.42057732630349115, 0.42057732630349115, 0.5246754623184993, 0.18095491995301308, 0.7238196798120523, 0.8941712568812392, 0.9005850581926784, 0.5247154616176177, 0.977645040670264], \"Term\": [\"\", \"05\", \"100\", \"100\", \"100\", \"100\", \"1010\", \"1010\", \"1010\", \"1010\", \"1010\", \"2\", \"2\", \"2\", \"2\", \"2\", \"2077\", \"2077\", \"2077\", \"2077\", \"2077\", \"210\", \"2d\", \"3\", \"3\", \"3\", \"3\", \"3\", \"610\", \"610\", \"9910\", \"aa\", \"actitud\", \"algumas\", \"alguns\", \"alone\", \"also\", \"also\", \"also\", \"also\", \"also\", \"ama\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amrketing\", \"ana\", \"armor\", \"armor\", \"armor\", \"armor\", \"around\", \"around\", \"around\", \"around\", \"around\", \"awesome\", \"awesome\", \"ayr\", \"ba\", \"back\", \"back\", \"back\", \"back\", \"better\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"big\", \"bir\", \"blue\", \"boa\", \"boost\", \"boost\", \"breathtaking\", \"bring\", \"bu\", \"bug\", \"bug\", \"bug\", \"bug\", \"bug\", \"build\", \"build\", \"build\", \"burn\", \"burn\", \"burn\", \"burn\", \"bye\", \"c\", \"c\", \"car\", \"car\", \"car\", \"car\", \"car\", \"cat\", \"cdpr\", \"cdpr\", \"cdpr\", \"cdpr\", \"cdpr\", \"character\", \"character\", \"character\", \"character\", \"character\", \"choice\", \"choice\", \"choice\", \"choose\", \"choose\", \"city\", \"city\", \"city\", \"city\", \"cleaner\", \"cloud\", \"code\", \"com\", \"con\", \"con\", \"con\", \"con\", \"con\", \"content\", \"content\", \"content\", \"cop\", \"cough\", \"country\", \"country\", \"craft\", \"craft\", \"cuerpo\", \"custom\", \"cute\", \"cyberpunk\", \"cyberpunk\", \"cyberpunk\", \"cyberpunk\", \"cyberpunk\", \"da\", \"da\", \"da\", \"daha\", \"dashboard\", \"ddr4\", \"de\", \"de\", \"de\", \"definitely\", \"definitely\", \"definitely\", \"del\", \"del\", \"denen\", \"der\", \"despair\", \"destroying\", \"destroying\", \"development\", \"development\", \"development\", \"dialogue\", \"dialogue\", \"different\", \"different\", \"different\", \"disgrace\", \"distracting\", \"distracting\", \"donde\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dx\", \"e\", \"e\", \"e\", \"e\", \"el\", \"el\", \"em\", \"em\", \"en\", \"en\", \"ending\", \"ending\", \"enga\", \"engage\", \"enjoyable\", \"enjoyed\", \"enjoyed\", \"ent\", \"esperabas\", \"esta\", \"este\", \"este\", \"estomago\", \"etc\", \"etc\", \"etc\", \"etc\", \"even\", \"even\", \"even\", \"even\", \"even\", \"every\", \"every\", \"every\", \"every\", \"exist\", \"exist\", \"exist\", \"exist\", \"experience\", \"experience\", \"experience\", \"f\", \"f\", \"f\", \"f\", \"f\", \"fake\", \"family\", \"family\", \"fantasize\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"felt\", \"felt\", \"fidelityfx\", \"fidelityfx\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fixed\", \"fortnite\", \"fov\", \"fun\", \"fun\", \"fun\", \"fun\", \"g\", \"game\", \"game\", \"game\", \"game\", \"game\", \"geile\", \"genital\", \"get\", \"get\", \"get\", \"get\", \"get\", \"glitchesbugs\", \"glowing\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gostei\", \"got\", \"got\", \"got\", \"got\", \"graphic\", \"graphic\", \"graphic\", \"great\", \"great\", \"great\", \"great\", \"great\", \"gun\", \"gun\", \"gun\", \"gun\", \"gun\", \"harika\", \"havent\", \"havent\", \"hi\", \"high\", \"high\", \"high\", \"high\", \"hissi\", \"hist\", \"hopefully\", \"hour\", \"hour\", \"hour\", \"hour\", \"hour\", \"iguana\", \"im\", \"im\", \"im\", \"im\", \"im\", \"implant\", \"implant\", \"implant\", \"insult\", \"interaction\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"istiyorum\", \"jogando\", \"jogo\", \"juego\", \"juego\", \"k\", \"k\", \"k\", \"kadar\", \"key\", \"key\", \"key\", \"key\", \"ki\", \"l\", \"la\", \"la\", \"la\", \"la\", \"large\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lisbon\", \"literalmente\", \"lo\", \"lo\", \"load\", \"look\", \"look\", \"look\", \"look\", \"look\", \"los\", \"los\", \"lot\", \"lot\", \"lot\", \"lot\", \"lower\", \"lower\", \"lower\", \"ma\", \"ma\", \"ma\", \"main\", \"main\", \"main\", \"main\", \"main\", \"mais\", \"make\", \"make\", \"make\", \"make\", \"make\", \"many\", \"many\", \"many\", \"many\", \"many\", \"meme\", \"meme\", \"meme\", \"might\", \"might\", \"might\", \"might\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"much\", \"much\", \"much\", \"much\", \"much\", \"muito\", \"muy\", \"muy\", \"n\", \"n\", \"n\", \"nda\", \"need\", \"need\", \"need\", \"need\", \"need\", \"night\", \"night\", \"night\", \"night\", \"o\", \"o\", \"o\", \"ok\", \"ok\", \"ok\", \"ok\", \"ok\", \"olarak\", \"olaylar\", \"olmas\", \"one\", \"one\", \"one\", \"one\", \"one\", \"outros\", \"overall\", \"oynan\", \"oyun\", \"oyunun\", \"packed\", \"packed\", \"panam\", \"panam\", \"panam\", \"para\", \"para\", \"para\", \"patada\", \"patch\", \"patch\", \"patch\", \"patch\", \"patch\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"people\", \"people\", \"people\", \"people\", \"people\", \"performance\", \"performance\", \"performance\", \"performance\", \"perk\", \"perk\", \"pet\", \"play\", \"play\", \"play\", \"play\", \"play\", \"playthrough\", \"please\", \"please\", \"please\", \"plug\", \"pon\", \"por\", \"por\", \"por\", \"porque\", \"principal\", \"principal\", \"quality\", \"quality\", \"quality\", \"que\", \"que\", \"que\", \"quest\", \"quest\", \"quest\", \"quest\", \"quest\", \"questsgigs\", \"questsgigs\", \"rather\", \"really\", \"really\", \"really\", \"really\", \"really\", \"recommend\", \"recommend\", \"recommend\", \"recommendation\", \"recommendation\", \"recommendation\", \"reflection\", \"reflection\", \"remap\", \"remapping\", \"resistance\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"ria\", \"rias\", \"rico\", \"ride\", \"ride\", \"ride\", \"ride\", \"rol\", \"samurai\", \"samurai\", \"samurai\", \"save\", \"save\", \"scattering\", \"se\", \"se\", \"se\", \"see\", \"see\", \"see\", \"see\", \"see\", \"setting\", \"setting\", \"setting\", \"setting\", \"shadow\", \"shadow\", \"shadow\", \"shooting\", \"si\", \"si\", \"side\", \"side\", \"side\", \"side\", \"side\", \"sikeyim\", \"simplemente\", \"smooth\", \"soon\", \"spiel\", \"statement\", \"still\", \"still\", \"still\", \"still\", \"still\", \"story\", \"story\", \"story\", \"story\", \"story\", \"subsurface\", \"tatmin\", \"taxing\", \"tem\", \"tem\", \"terrarium\", \"thats\", \"thats\", \"thats\", \"thats\", \"there\", \"there\", \"there\", \"there\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thru\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tit\", \"todo\", \"took\", \"true\", \"true\", \"tu\", \"turn\", \"turn\", \"turn\", \"turn\", \"u\", \"u\", \"u\", \"u\", \"u\", \"um\", \"uma\", \"un\", \"una\", \"und\", \"update\", \"update\", \"ur\", \"ur\", \"v\", \"v\", \"v\", \"v\", \"v\", \"vale\", \"vale\", \"var\", \"vending\", \"vending\", \"ver\", \"vers\", \"viele\", \"volumetric\", \"volumetric\", \"vorpx\", \"vram\", \"wake\", \"wake\", \"want\", \"want\", \"want\", \"wave\", \"way\", \"way\", \"way\", \"way\", \"way\", \"well\", \"well\", \"well\", \"well\", \"well\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"would\", \"would\", \"would\", \"would\", \"would\", \"wow\", \"wow\", \"wreck\", \"ya\", \"ya\", \"yan\", \"yapma\", \"ye\", \"z\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 2, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el421215798953516247932935562\", ldavis_el421215798953516247932935562_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el421215798953516247932935562\", ldavis_el421215798953516247932935562_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el421215798953516247932935562\", ldavis_el421215798953516247932935562_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.162776 -0.021000       1        1  84.711068\n",
       "2      0.052786  0.014775       2        1   5.393701\n",
       "1     -0.005700 -0.011708       3        1   3.836284\n",
       "3     -0.130668 -0.077550       4        1   3.626369\n",
       "4     -0.079193  0.095483       5        1   2.432578, topic_info=          Term         Freq        Total Category  logprob  loglift\n",
       "33        game  2713.000000  2713.000000  Default  30.0000  30.0000\n",
       "135       like   651.000000   651.000000  Default  29.0000  29.0000\n",
       "14         bug   621.000000   621.000000  Default  28.0000  28.0000\n",
       "65      really   402.000000   402.000000  Default  27.0000  27.0000\n",
       "16   character   469.000000   469.000000  Default  26.0000  26.0000\n",
       "..         ...          ...          ...      ...      ...      ...\n",
       "517      panam     2.447188    25.229776   Topic5  -6.5885   1.3831\n",
       "30        feel     3.033243   371.151084   Topic5  -6.3738  -1.0908\n",
       "511          2     2.531477    81.837072   Topic5  -6.5546   0.2403\n",
       "0         2077     2.514487   154.497644   Topic5  -6.5613  -0.4019\n",
       "191          u     2.511643    74.599510   Topic5  -6.5625   0.3250\n",
       "\n",
       "[372 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "3426      5  0.814500       \n",
       "8017      2  0.524989     05\n",
       "729       1  0.870473    100\n",
       "729       2  0.044640    100\n",
       "729       4  0.022320    100\n",
       "...     ...       ...    ...\n",
       "3877      4  0.723820     ya\n",
       "5768      4  0.894171    yan\n",
       "5774      4  0.900585  yapma\n",
       "2271      2  0.524715     ye\n",
       "5791      4  0.977645      z\n",
       "\n",
       "[688 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 2, 4, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(X_split_pos)\n",
    "corpus = [id2word.doc2bow(review) for review in X_split_pos]\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=10, iterations=100, random_state=212)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\anaconda3\\envs\\capstone\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el421215798939424723023762752\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el421215798939424723023762752_data = {\"mdsDat\": {\"x\": [0.045734030843470275, 0.022307030358178177, 0.00878682405189762, 0.013749081385546029, -0.09057696663909198], \"y\": [-0.0011777639673157085, 0.016663823346911057, 0.05240888948424601, -0.06640798592213125, -0.0014869629417101002], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [43.82042717856638, 19.09611428212385, 18.99989246535162, 12.983937843582863, 5.099628230375281]}, \"tinfo\": {\"Term\": [\"game\", \"bug\", \"even\", \"still\", \"really\", \"2077\", \"cyberpunk\", \"time\", \"recommend\", \"one\", \"review\", \"setting\", \"dialogue\", \"cdpr\", \"year\", \"hour\", \"feel\", \"story\", \"say\", \"get\", \"dont\", \"state\", \"much\", \"wait\", \"cant\", \"like\", \"preordering\", \"ive\", \"high\", \"player\", \"pacing\", \"bois\", \"comparing\", \"op\", \"spam\", \"wise\", \"conversation\", \"gear\", \"popping\", \"quickhack\", \"claim\", \"unno\", \"twice\", \"treated\", \"monster\", \"boxing\", \"occasionally\", \"adding\", \"perspective\", \"lvl\", \"attribute\", \"plenty\", \"engine\", \"firearm\", \"netrunner\", \"superb\", \"sign\", \"funniest\", \"picture\", \"neck\", \"crafting\", \"across\", \"towards\", \"stuck\", \"click\", \"loot\", \"seriously\", \"ahead\", \"pointless\", \"ran\", \"useless\", \"cover\", \"mission\", \"close\", \"upgrade\", \"awesome\", \"limited\", \"lore\", \"combat\", \"rest\", \"background\", \"like\", \"car\", \"getting\", \"weapon\", \"character\", \"take\", \"game\", \"actually\", \"pretty\", \"good\", \"get\", \"much\", \"there\", \"time\", \"stealth\", \"story\", \"feel\", \"main\", \"item\", \"one\", \"enemy\", \"cant\", \"side\", \"system\", \"bad\", \"go\", \"dont\", \"many\", \"would\", \"thing\", \"look\", \"ai\", \"even\", \"city\", \"bug\", \"make\", \"really\", \"im\", \"world\", \"npc\", \"quest\", \"preordering\", \"l\", \"r\", \"yle\", \"yak\", \"bir\", \"v104\", \"hp\", \"bounty\", \"mi\", \"tw3\", \"outright\", \"conceiving\", \"k\", \"tek\", \"pasted\", \"mmo\", \"nvme\", \"40fps\", \"turnoff\", \"artistic\", \"poof\", \"i9\", \"perfectly\", \"trade\", \"quote\", \"granted\", \"facility\", \"increasingly\", \"apparent\", \"directly\", \"g\", \"dmg\", \"c\", \"stop\", \"fetch\", \"happy\", \"b\", \"w\", \"cp\", \"p\", \"mean\", \"setting\", \"e\", \"step\", \"genuinely\", \"world\", \"game\", \"really\", \"around\", \"youre\", \"bug\", \"play\", \"optimization\", \"want\", \"dont\", \"character\", \"like\", \"open\", \"playing\", \"review\", \"well\", \"right\", \"thats\", \"think\", \"feel\", \"cyberpunk\", \"even\", \"would\", \"get\", \"gameplay\", \"quest\", \"story\", \"cant\", \"good\", \"look\", \"make\", \"im\", \"npc\", \"city\", \"way\", \"time\", \"one\", \"ai\", \"que\", \"jogo\", \"voc\", \"um\", \"eles\", \"o\", \"com\", \"hist\", \"ria\", \"muito\", \"pra\", \"tem\", \"mais\", \"uma\", \"mesmo\", \"eu\", \"por\", \"simplesmente\", \"nem\", \"como\", \"vel\", \"seu\", \"personagem\", \"ma\", \"personagens\", \"assim\", \"est\", \"de\", \"20201215\", \"proof\", \"em\", \"se\", \"crash\", \"player\", \"n\", \"wait\", \"bugged\", \"e\", \"game\", \"min\", \"fix\", \"even\", \"npc\", \"bug\", \"patch\", \"cannot\", \"year\", \"mind\", \"world\", \"recommend\", \"issue\", \"like\", \"still\", \"story\", \"buy\", \"time\", \"cyberpunk\", \"make\", \"without\", \"dont\", \"one\", \"good\", \"city\", \"look\", \"quest\", \"play\", \"car\", \"ai\", \"would\", \"really\", \"feel\", \"get\", \"character\", \"blue\", \"ammo\", \"customer\", \"choicedriven\", \"schematic\", \"dismantle\", \"adult\", \"sin\", \"butterfly\", \"ironically\", \"overrated\", \"acclaimed\", \"terribly\", \"sake\", \"advance\", \"preanimated\", \"completly\", \"valve\", \"trans\", \"intersting\", \"130h\", \"smoothed\", \"everybody\", \"mandatory\", \"lovingly\", \"address\", \"cyberspace\", \"unengaging\", \"exploitation\", \"analysis\", \"scam\", \"yellow\", \"demand\", \"destiny\", \"interview\", \"modded\", \"exciting\", \"substance\", \"delivered\", \"cred\", \"dialogue\", \"paid\", \"u\", \"changed\", \"game\", \"buggy\", \"2\", \"cdpr\", \"cyberpunk\", \"feel\", \"choice\", \"video\", \"2077\", \"like\", \"way\", \"rpg\", \"bland\", \"choose\", \"impact\", \"nothing\", \"promised\", \"thing\", \"story\", \"one\", \"option\", \"year\", \"get\", \"first\", \"character\", \"review\", \"play\", \"playing\", \"even\", \"dont\", \"time\", \"bug\", \"world\", \"make\", \"go\", \"really\", \"good\", \"gay\", \"rofl\", \"lmao\", \"cmon\", \"pogchamp\", \"cyberbug\", \"345\", \"coding\", \"punk\", \"renamed\", \"messing\", \"reviewing\", \"autosave\", \"circling\", \"router\", \"brutal\", \"ofc\", \"dec\", \"amounted\", \"revew\", \"excluded\", \"howd\", \"smoothing\", \"pls\", \"uneven\", \"witnessed\", \"eathat\", \"realcrowbcats\", \"softlocking\", \"bleed\", \"policy\", \"check\", \"profile\", \"noticeable\", \"forbid\", \"dick\", \"remapping\", \"wholesome\", \"held\", \"self\", \"illegal\", \"23\", \"explained\", \"frustrating\", \"1060\", \"spec\", \"steam\", \"hence\", \"text\", \"accept\", \"game\", \"still\", \"refund\", \"2077\", \"high\", \"bug\", \"recommend\", \"even\", \"setting\", \"review\", \"rtx\", \"cd\", \"current\", \"state\", \"time\", \"pc\", \"gtx\", \"really\", \"say\", \"one\", \"hour\", \"ive\", \"much\", \"cant\", \"get\", \"cyberpunk\", \"story\", \"dont\", \"quest\", \"great\", \"year\", \"like\", \"make\", \"im\", \"would\", \"people\"], \"Freq\": [2153.0, 399.0, 399.0, 144.0, 287.0, 103.0, 211.0, 323.0, 121.0, 312.0, 124.0, 110.0, 123.0, 157.0, 178.0, 153.0, 365.0, 398.0, 114.0, 334.0, 320.0, 97.0, 213.0, 118.0, 237.0, 655.0, 31.0, 127.0, 44.0, 102.0, 8.07149578830102, 6.096591339670709, 9.570496221945195, 6.068097724027726, 6.893507742116552, 11.24218055171008, 13.768729398767112, 20.698632675686127, 5.140214972877548, 5.133522331835544, 5.1325329996678075, 5.120513250738925, 6.799025246279436, 5.087434314031825, 5.080558243163013, 5.071714123110742, 5.069901055146692, 8.469156367001583, 5.040599838738457, 5.023269541559839, 16.816591758097243, 10.885644770337409, 4.150679418828058, 4.149247222518283, 4.143614398253391, 4.141628091008466, 4.141667154767879, 4.139094041919602, 4.138628673655294, 4.1380660705985335, 47.746355915159526, 13.261774365714698, 8.028576605676623, 33.8329725660747, 10.590186026018793, 33.7325073705623, 14.559747598147704, 9.014042310443813, 23.303529836730632, 12.80076255979253, 22.112458827991524, 20.068360997076994, 121.75471340666094, 21.70138239556915, 18.959706028577255, 21.520768556287646, 29.140650769653917, 16.723689646092023, 82.98344983696204, 24.442744554061424, 18.31383941784081, 352.7002569004208, 118.98194738244943, 42.39537157915812, 70.23141507097615, 209.69017072207404, 53.34527623372957, 914.4680693411514, 69.7431860152892, 64.9912529220045, 157.29007102055033, 180.89020688722928, 123.52849341928763, 74.63644839328072, 173.02847244721684, 43.967816975771306, 202.37704092555748, 188.03807320348923, 88.11856783844837, 48.11391531959605, 162.48583635773718, 74.34017525449956, 127.73010985735955, 90.87337132702729, 89.8495000022722, 88.35223705670973, 93.50587467700637, 152.92819126342664, 109.10141144337871, 122.85328143311057, 114.91579726832376, 111.04211939209786, 105.40577599201036, 168.50002481995702, 109.99360732727492, 156.91321104452493, 114.71406522101883, 126.81580048878708, 96.76707356782352, 110.51922209914422, 100.75400237786005, 90.85256902592782, 29.45492395838349, 10.56326161640395, 9.702411491034878, 6.23876368601638, 6.2349534389541175, 5.373205892341261, 5.358401587419082, 5.2726010851717495, 4.364615435514279, 3.6350053030478384, 3.630728396938809, 3.5608231677896027, 2.774606848865584, 2.7738469088556426, 2.77233813095424, 2.7716694133511406, 2.770491848651051, 2.768844664339267, 2.7678221592272787, 2.765879103458008, 2.765412259375933, 2.7639436341363655, 2.763755268192825, 2.7608565050577525, 2.7623882273373472, 2.7600503062208124, 2.757672047407134, 2.7567159699707164, 2.7593669708283812, 2.755348003938699, 6.169268495109694, 9.699049029417967, 5.355923224503777, 7.094259629713269, 35.167194840297896, 4.483140542192629, 4.505690795178155, 13.745553613777851, 4.477720117880182, 5.525764173148779, 10.50213409219548, 24.997100687172168, 39.900356570937774, 19.23938217304891, 8.102672452644574, 5.7833325817385886, 79.66979696076191, 365.52482249539474, 78.7445019981826, 38.57491165269769, 29.457091091910744, 87.58895287521808, 54.43561127359514, 19.536510390347125, 34.99657748350054, 69.87086587208746, 78.35654957002495, 113.05074679404511, 34.02476612477339, 35.127156160212394, 35.861873637250156, 40.29431598533422, 30.459754497751984, 32.728234083619604, 28.121512159922315, 65.46392879085762, 46.83463319307486, 67.42465765246557, 50.383420924291144, 58.79562340071708, 34.94903969245256, 44.45297121001198, 63.16695672812348, 46.85635189738625, 48.85502039854578, 42.868571598654576, 44.95390767751472, 40.29065376651835, 42.24780330512842, 40.96668100442457, 38.40503443713232, 42.464608435366614, 41.760713399793666, 38.49450270925476, 20.846153656742707, 17.38759565639043, 12.233166713403588, 11.367938083878645, 8.789300128383374, 8.782962568466194, 7.92843547516208, 7.923175285702585, 7.065575882385168, 7.059699316252344, 6.200898088883703, 5.340803722401121, 5.340720507868163, 5.338572762864857, 4.480002768800189, 4.4800016641824945, 4.479764171378255, 4.478580757621933, 4.476831779606211, 3.6174981265089947, 3.6169697510452976, 3.6166361565016674, 3.616544841438952, 3.615605548193035, 3.61472995456748, 3.6146172835626778, 3.613539176693197, 28.61909799039507, 2.763901305406294, 2.7617172921220305, 17.41383695433242, 5.342731648483293, 25.667851130724298, 50.12623131013367, 19.98787601816109, 51.620811452424086, 9.569506333990363, 22.56885649957973, 471.73804424200836, 8.25405688827605, 37.249364100117724, 101.2127671675505, 66.13624793039699, 92.17392506511935, 30.25766431270484, 27.52900233687405, 49.70695967249871, 17.148073301240302, 61.65740316914615, 36.07486681782286, 39.187063839647784, 97.09368018822154, 38.83719164967666, 70.57419532613997, 31.32767359807562, 58.76797071563945, 46.282052745580714, 47.614448499546725, 26.02281045338283, 52.7615781288107, 50.262349666523555, 47.346114769286245, 41.969336594234164, 41.511191250707036, 40.47026728563476, 41.14043442219871, 38.95482017869024, 38.655672033234026, 40.83862635733501, 42.656314539279336, 44.24812165818437, 42.78598781962982, 42.26694122056577, 4.226390072215706, 4.178453850241308, 3.4158927546788194, 3.413046423551979, 3.3869850816025995, 3.336200263916837, 2.610236363993886, 2.6097990475601476, 2.6058637028975076, 2.6027697771959843, 2.5963016205529006, 2.5954325233364837, 2.555922820377889, 2.5475061145616924, 3.158460573200995, 2.4158736163859302, 1.7973694103725746, 1.796019214754945, 1.7960702937169986, 1.7947525571442204, 1.7939318968745785, 1.7937863344137512, 1.7936518432550441, 1.7935514466744562, 1.7936305813225637, 1.792960390113552, 1.793148099008586, 1.7923861921263307, 1.7921062643170476, 1.7915128173613675, 7.055254206997963, 3.4096923222506366, 3.400267121459513, 3.3966802711931487, 2.867803917302177, 3.3889821935327387, 4.961047963748857, 5.5090316237553605, 5.016325465510799, 4.097285101989829, 40.42849421781809, 4.091305843983544, 21.170998843655624, 7.3687179968844, 306.36626393822223, 20.76069034819786, 27.11286805620086, 37.81545354332132, 45.115741331525264, 63.685652481045636, 32.63064198270294, 14.087693479772723, 24.72709101976653, 81.73248285171432, 34.295000895216575, 32.52596785356878, 7.967081617187779, 12.613062465206827, 11.547236261974406, 29.138324532731048, 18.046945109617933, 35.83352540079877, 49.206575387066195, 42.17744190445626, 23.957174553668345, 29.514495171342926, 39.64403006073428, 21.586790653108803, 40.9885410679663, 22.155042344609914, 29.198860399758967, 21.10017069158419, 38.439701867981164, 33.01724782680389, 32.41045995206923, 32.933270993741985, 26.909804271608625, 24.745050684769126, 22.50337369080015, 23.599342017295164, 22.181967751365658, 2.0306994097280393, 2.0287021045493407, 1.9997740890388385, 1.397513247604645, 1.3975108757429782, 1.3973544317005298, 1.3971914650384976, 1.3963752481423632, 1.3960416062678809, 1.3946167103714695, 1.3937355637622029, 1.3891035155818166, 1.3886987178573262, 1.3872655204450803, 2.6661417064345367, 2.664536351396299, 0.7619944089456042, 0.7619926794631388, 0.761993173600986, 0.761992827704493, 0.7619908511531038, 0.7619886275327911, 0.7619880345673743, 0.7619867992227561, 0.7619854650505684, 0.7619845261886586, 0.7619766693968869, 0.7619751375695604, 0.7619722715700461, 0.7619591769170933, 1.782948773514808, 6.258944466283038, 1.3960423968884366, 1.3913458143051958, 1.0894404372022126, 1.3882918447538772, 1.398621796451229, 1.3979488795308055, 1.3944267637829757, 1.3944959430815946, 1.3923910146797587, 2.6194085207006266, 1.3882497442092891, 4.1800409212773095, 4.38257814211972, 7.413670297040083, 7.2814224060767545, 1.9169472960434744, 3.738452459850571, 2.558795595802087, 94.93702057578716, 16.43335184737894, 5.935535198342199, 13.080813140047127, 7.700804707957086, 29.84446807130185, 12.914141630091006, 23.706012596458034, 11.517243188795945, 12.022435492683227, 5.818434015983921, 6.175461655881627, 8.625200633479125, 9.56830659445051, 17.131601041025892, 7.464511151870848, 3.888676690387605, 15.385499731472345, 9.705595482076632, 15.443153363631104, 10.554301348703978, 9.722329756757418, 11.753769977946098, 11.74444698035393, 12.629315831196488, 10.435432338783277, 12.91579086457008, 12.000192173970706, 9.804520297860627, 8.683821194577439, 8.967066542981224, 11.324462225610196, 9.01408158494322, 8.754229117539868, 8.91760690226117, 8.515532865585024], \"Total\": [2153.0, 399.0, 399.0, 144.0, 287.0, 103.0, 211.0, 323.0, 121.0, 312.0, 124.0, 110.0, 123.0, 157.0, 178.0, 153.0, 365.0, 398.0, 114.0, 334.0, 320.0, 97.0, 213.0, 118.0, 237.0, 655.0, 31.0, 127.0, 44.0, 102.0, 8.754244670133172, 6.772273081684795, 10.645244287540164, 6.76889937831007, 7.697475275387715, 12.613777438968318, 15.48555915508149, 23.280854646257648, 5.787011834505604, 5.785482528898386, 5.784881516191876, 5.783713182559635, 7.704524349198548, 5.776749283234977, 5.777204865143219, 5.77785514792561, 5.776953882614581, 9.665825491211653, 5.7680913658257404, 5.766029723292957, 19.33339471390602, 12.574046215050153, 4.796345128897054, 4.796041346403152, 4.794307962796846, 4.7935448570192305, 4.794085936939315, 4.792468659766054, 4.79297828206617, 4.792884879691846, 56.018424968064316, 15.410103916389327, 9.371287486425919, 40.73294116252512, 12.465791926388102, 41.190772667420056, 17.364396570005994, 10.604444121743766, 28.657652705228454, 15.374146123528089, 27.604078778491633, 24.911073352057475, 180.26625033515037, 27.681696751731383, 23.96575710694055, 27.66356663254902, 38.6600930179913, 21.0716843683289, 127.32514956349314, 32.348222328004695, 23.45388508678687, 655.901628960012, 194.38384454782636, 60.23683718885285, 107.43938156703508, 379.7290301917344, 79.21638775434819, 2153.034220592564, 109.19943397752884, 100.67509256923792, 283.4230603717996, 334.745163999507, 213.87210292280082, 119.38322416899321, 323.80311259131804, 64.14885625123559, 398.2405592314572, 365.8199616072862, 147.05595339995608, 71.4763697192542, 312.1294946921418, 120.73908971725747, 237.62197559173035, 158.2425227659925, 158.0256145000575, 156.35320201835316, 168.38006115002733, 320.5780752650994, 206.3666482039907, 244.90094902981525, 223.52649178981042, 213.69414223798103, 202.00367150462566, 399.2831641044123, 217.54596379218867, 399.4538280499062, 241.0415536677926, 287.20145877501653, 192.48824795923434, 282.91773013708024, 237.05872760989098, 203.50875363337695, 31.36010203519138, 11.259524302867616, 10.39030311637346, 6.910073560619812, 6.909046232674513, 6.042336033863877, 6.045260313692862, 6.0554386065070664, 5.167899566062817, 4.3049450144097, 4.306338389745328, 4.305739825783051, 3.439373090870409, 3.4384680162667394, 3.4379803928103936, 3.4384580461240213, 3.4394822717804514, 3.439731785193729, 3.4391480774804473, 3.437686239124003, 3.4391786482696993, 3.4393074862841426, 3.4391335645568684, 3.4370544517888577, 3.439365376982448, 3.439327985281556, 3.4366710896130224, 3.435609277316226, 3.4404915340841953, 3.4390577663724042, 7.732033399188774, 12.368629319995684, 6.8617239316640966, 9.761978009474998, 58.9011530460692, 5.992938104390669, 6.038889209970045, 23.259021339992156, 6.166363222379008, 7.995096890664589, 18.06865497366301, 54.600868378235496, 110.90251588616606, 43.32219707904372, 13.931151225890925, 8.95564162996761, 282.91773013708024, 2153.034220592564, 287.20145877501653, 118.01803620401881, 85.43978872453967, 399.4538280499062, 215.46317778197007, 49.55265516349586, 115.67519173866302, 320.5780752650994, 379.7290301917344, 655.901628960012, 112.65750117892134, 119.77762048437481, 124.5051887361735, 154.0496662786756, 98.69262184793926, 111.65512113569618, 89.27575842844041, 365.8199616072862, 211.06442969379842, 399.2831641044123, 244.90094902981525, 334.745163999507, 129.9205979828301, 203.50875363337695, 398.2405592314572, 237.62197559173035, 283.4230603717996, 213.69414223798103, 241.0415536677926, 192.48824795923434, 237.05872760989098, 217.54596379218867, 174.96288303184173, 323.80311259131804, 312.1294946921418, 202.00367150462566, 21.580422856222715, 18.123987304120977, 12.9355706931692, 12.071555559245926, 9.47784375052726, 9.478733113942443, 8.6133328444998, 8.61422696303008, 7.749140438047534, 7.749381430465441, 6.8850514320706715, 6.020342092124368, 6.0203101542346396, 6.020528178112207, 5.155910032133941, 5.155935822849518, 5.156038321409921, 5.1559629782632115, 5.1564249678169745, 4.291530811279435, 4.291595036470299, 4.291559976874719, 4.291693115314178, 4.291726426490283, 4.291634844494018, 4.291820422230332, 4.291771725060514, 34.68456372342809, 3.4265950204917646, 3.42657946140637, 23.552875411967214, 7.006708655596218, 45.496276723524254, 102.58747694303273, 33.744164458009216, 118.23725172871876, 14.48556156615383, 43.32219707904372, 2153.034220592564, 12.51982848543416, 98.96559452596404, 399.2831641044123, 237.05872760989098, 399.4538280499062, 80.81059822529848, 73.50709199361646, 178.27350166680495, 37.20951781570692, 282.91773013708024, 121.68014705149359, 140.09136389007588, 655.901628960012, 144.2039920188722, 398.2405592314572, 101.81846512621024, 323.80311259131804, 211.06442969379842, 241.0415536677926, 79.03746198325229, 320.5780752650994, 312.1294946921418, 283.4230603717996, 217.54596379218867, 213.69414223798103, 203.50875363337695, 215.46317778197007, 194.38384454782636, 202.00367150462566, 244.90094902981525, 287.20145877501653, 365.8199616072862, 334.745163999507, 379.7290301917344, 4.923829857640723, 4.931407813261564, 4.10599973768738, 4.106551524025213, 4.112142293064641, 4.09173430063423, 3.2869777184187865, 3.2876970391019196, 3.2886826615298816, 3.28844947598536, 3.288472473163022, 3.2898907224696994, 3.288241264439899, 3.299201222953177, 4.146826260953773, 3.3040941005059024, 2.469871733857524, 2.470075370140066, 2.470207035799032, 2.469540419265385, 2.4693181951557244, 2.4693823755212048, 2.4698749792875527, 2.469894833053285, 2.470431976810894, 2.4705488788321097, 2.470947873631059, 2.4700457313366706, 2.4701256238702483, 2.469723719951278, 10.265355201521817, 4.97228048356455, 4.977184130150255, 4.9778776558099445, 4.136021733604954, 4.978810879027, 8.596762622022744, 9.819459369482901, 8.868858555631448, 6.932451860397413, 123.32024659318046, 6.934004090521325, 58.068345291955595, 15.25797620705397, 2153.034220592564, 61.5095157962682, 89.86313141431697, 157.2716790806135, 211.06442969379842, 365.8199616072862, 148.25840308832178, 42.439900177295854, 103.04761886313503, 655.901628960012, 174.96288303184173, 167.65748549496408, 18.769455156203087, 38.6395034513922, 33.64004701498632, 147.19953392044596, 70.8623666816321, 223.52649178981042, 398.2405592314572, 312.1294946921418, 122.4122763258181, 178.27350166680495, 334.745163999507, 112.40994958975115, 379.7290301917344, 124.5051887361735, 215.46317778197007, 119.77762048437481, 399.2831641044123, 320.5780752650994, 323.80311259131804, 399.4538280499062, 282.91773013708024, 241.0415536677926, 168.38006115002733, 287.20145877501653, 283.4230603717996, 2.7423750387913213, 2.742906791357938, 2.7519476384353503, 2.1059847349323144, 2.105985323733835, 2.1059150358513516, 2.105826509637541, 2.106364308746247, 2.106594569324894, 2.1071058620576175, 2.1073707049040387, 2.108469863290896, 2.108984758533837, 2.109381529132645, 4.201015747630361, 4.240547289072055, 1.4704369484150264, 1.4704350281134075, 1.4704360115166244, 1.4704355389555748, 1.4704340377956933, 1.470432170719262, 1.4704323918171887, 1.4704312323947586, 1.4704302928774373, 1.4704351408124272, 1.470425101996165, 1.4704237872320287, 1.4704219934106553, 1.4704146396289755, 3.634017523279544, 14.695016750740677, 2.923545864191646, 2.924679616650356, 2.2081836379654938, 2.9263576780952065, 2.9678326929240244, 2.97226763307748, 2.968950016746928, 2.9730937821431604, 2.970073829164218, 6.2484924183360055, 2.9713194506691583, 11.184281816073952, 12.512019605439885, 27.167480896702855, 28.70164525630743, 4.632266175820714, 13.583173945610238, 7.5980143175196915, 2153.034220592564, 144.2039920188722, 28.800761329515034, 103.04761886313503, 44.54837075818196, 399.4538280499062, 121.68014705149359, 399.2831641044123, 110.90251588616606, 124.5051887361735, 31.579119755658088, 36.71188563663121, 77.53879300613615, 97.6035970395129, 323.80311259131804, 61.4107564250306, 16.881515683169575, 287.20145877501653, 114.68559816392825, 312.1294946921418, 153.0024389000721, 127.26979672333158, 213.87210292280082, 237.62197559173035, 334.745163999507, 211.06442969379842, 398.2405592314572, 320.5780752650994, 203.50875363337695, 142.21898778636105, 178.27350166680495, 655.901628960012, 241.0415536677926, 192.48824795923434, 244.90094902981525, 160.62719774247174], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.1929, -8.4735, -8.0225, -8.4781, -8.3506, -7.8615, -7.6588, -7.2511, -8.6441, -8.6454, -8.6456, -8.6479, -8.3644, -8.6544, -8.6558, -8.6575, -8.6579, -8.1448, -8.6637, -8.6671, -7.4588, -7.8937, -8.8579, -8.8583, -8.8596, -8.8601, -8.8601, -8.8607, -8.8608, -8.861, -6.4153, -7.6963, -8.1982, -6.7598, -7.9213, -6.7627, -7.6029, -8.0824, -7.1326, -7.7317, -7.1851, -7.2821, -5.4792, -7.2038, -7.3389, -7.2122, -6.9091, -7.4644, -5.8626, -7.0849, -7.3735, -4.4156, -5.5022, -6.5342, -6.0294, -4.9356, -6.3044, -3.4629, -6.0364, -6.1069, -5.2231, -5.0833, -5.4647, -5.9686, -5.1277, -6.4977, -4.9711, -5.0446, -5.8025, -6.4076, -5.1906, -5.9725, -5.4313, -5.7717, -5.7831, -5.7999, -5.7432, -5.2512, -5.5889, -5.4702, -5.537, -5.5713, -5.6234, -5.1543, -5.5808, -5.2255, -5.5388, -5.4385, -5.7089, -5.576, -5.6685, -5.772, -6.0677, -7.0932, -7.1782, -7.6198, -7.6204, -7.7692, -7.7719, -7.7881, -7.977, -8.16, -8.1611, -8.1806, -8.4301, -8.4303, -8.4309, -8.4311, -8.4316, -8.4321, -8.4325, -8.4332, -8.4334, -8.4339, -8.434, -8.435, -8.4345, -8.4353, -8.4362, -8.4365, -8.4356, -8.437, -7.631, -7.1786, -7.7724, -7.4913, -5.8905, -7.9503, -7.9452, -6.8299, -7.9515, -7.7412, -7.099, -6.2318, -5.7642, -6.4936, -7.3584, -7.6956, -5.0727, -3.5492, -5.0844, -5.798, -6.0676, -4.9779, -5.4536, -6.4783, -5.8953, -5.2039, -5.0893, -4.7227, -5.9235, -5.8916, -5.8709, -5.7544, -6.0342, -5.9623, -6.114, -5.2691, -5.604, -5.2396, -5.5309, -5.3765, -5.8967, -5.6561, -5.3048, -5.6035, -5.5617, -5.6924, -5.6449, -5.7545, -5.707, -5.7378, -5.8024, -5.7019, -5.7186, -5.8001, -6.4084, -6.5898, -6.9414, -7.0147, -7.272, -7.2727, -7.3751, -7.3757, -7.4903, -7.4911, -7.6208, -7.7702, -7.7702, -7.7706, -7.9459, -7.9459, -7.946, -7.9462, -7.9466, -8.1597, -8.1599, -8.16, -8.16, -8.1603, -8.1605, -8.1605, -8.1608, -6.0915, -8.4289, -8.4297, -6.5883, -7.7698, -6.2003, -5.531, -6.4504, -5.5016, -7.1869, -6.329, -3.2891, -7.3348, -5.8279, -4.8283, -5.2538, -4.9219, -6.0358, -6.1303, -5.5394, -6.6036, -5.3239, -5.8599, -5.7772, -4.8699, -5.7861, -5.1889, -6.001, -5.3719, -5.6108, -5.5824, -6.1866, -5.4797, -5.5283, -5.588, -5.7086, -5.7196, -5.745, -5.7285, -5.7831, -5.7908, -5.7359, -5.6924, -5.6557, -5.6893, -5.7015, -7.6235, -7.6349, -7.8364, -7.8372, -7.8449, -7.86, -8.1054, -8.1055, -8.107, -8.1082, -8.1107, -8.1111, -8.1264, -8.1297, -7.9147, -8.1827, -8.4785, -8.4792, -8.4792, -8.4799, -8.4804, -8.4805, -8.4806, -8.4806, -8.4806, -8.4809, -8.4808, -8.4813, -8.4814, -8.4817, -7.111, -7.8382, -7.841, -7.842, -8.0113, -7.8443, -7.4632, -7.3584, -7.4521, -7.6545, -5.3653, -7.6559, -6.0122, -7.0676, -3.34, -6.0317, -5.7648, -5.4321, -5.2556, -4.9108, -5.5796, -6.4195, -5.8569, -4.6614, -5.5298, -5.5828, -6.9895, -6.5301, -6.6184, -5.6928, -6.1718, -5.4859, -5.1688, -5.3229, -5.8885, -5.6799, -5.3849, -5.9927, -5.3515, -5.9667, -5.6907, -6.0155, -5.4157, -5.5678, -5.5863, -5.5703, -5.7723, -5.8562, -5.9511, -5.9036, -5.9655, -7.4219, -7.4229, -7.4372, -7.7956, -7.7956, -7.7957, -7.7958, -7.7964, -7.7966, -7.7976, -7.7983, -7.8016, -7.8019, -7.8029, -7.1496, -7.1502, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -8.4021, -7.552, -6.2963, -7.7966, -7.8, -8.0446, -7.8022, -7.7948, -7.7953, -7.7978, -7.7977, -7.7992, -7.1673, -7.8022, -6.6999, -6.6526, -6.1269, -6.1449, -7.4795, -6.8116, -7.1907, -3.577, -5.3309, -6.3493, -5.5591, -6.0889, -4.7343, -5.5719, -4.9645, -5.6864, -5.6435, -6.3692, -6.3097, -5.9756, -5.8718, -5.2893, -6.1201, -6.7722, -5.3968, -5.8576, -5.3931, -5.7737, -5.8558, -5.6661, -5.6669, -5.5942, -5.7851, -5.5718, -5.6453, -5.8474, -5.9688, -5.9367, -5.7033, -5.9315, -5.9607, -5.9422, -5.9884], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7439, 0.72, 0.7186, 0.7158, 0.7148, 0.71, 0.7076, 0.7075, 0.7065, 0.7055, 0.7054, 0.7033, 0.7, 0.698, 0.6966, 0.6947, 0.6945, 0.6929, 0.6903, 0.6872, 0.6856, 0.6809, 0.6805, 0.6802, 0.6792, 0.6789, 0.6788, 0.6785, 0.6783, 0.6782, 0.6653, 0.6749, 0.6704, 0.6395, 0.662, 0.6253, 0.6489, 0.6626, 0.6183, 0.6419, 0.6032, 0.6089, 0.4326, 0.5817, 0.5908, 0.574, 0.5424, 0.594, 0.397, 0.5448, 0.5777, 0.2047, 0.3342, 0.4738, 0.3999, 0.2312, 0.4297, -0.0312, 0.3767, 0.3874, 0.2362, 0.2096, 0.2762, 0.3554, 0.1984, 0.4473, 0.1481, 0.1596, 0.3129, 0.4293, 0.1722, 0.3401, 0.2043, 0.2704, 0.2604, 0.2543, 0.2369, 0.0849, 0.1877, 0.1352, 0.1597, 0.1704, 0.1746, -0.0377, 0.1431, -0.1093, 0.0825, 0.0076, 0.1373, -0.1149, -0.0306, 0.0186, 1.593, 1.5919, 1.5872, 1.5535, 1.553, 1.5383, 1.5351, 1.5173, 1.4867, 1.4865, 1.485, 1.4657, 1.4409, 1.4409, 1.4405, 1.4401, 1.4394, 1.4387, 1.4385, 1.4382, 1.4376, 1.4371, 1.4371, 1.4366, 1.4365, 1.4357, 1.4356, 1.4355, 1.4351, 1.434, 1.4299, 1.4125, 1.4079, 1.3365, 1.1399, 1.3654, 1.3628, 1.1297, 1.3357, 1.2863, 1.1131, 0.8744, 0.6334, 0.844, 1.1138, 1.2184, 0.3884, -0.1176, 0.3617, 0.5374, 0.5908, 0.1382, 0.2799, 0.7249, 0.4601, 0.1322, 0.0775, -0.1025, 0.4584, 0.429, 0.411, 0.3146, 0.4801, 0.4285, 0.5005, -0.065, 0.1501, -0.123, 0.0745, -0.0836, 0.3427, 0.1344, -0.1856, 0.0321, -0.1024, 0.0493, -0.0236, 0.0918, -0.0691, -0.014, 0.1393, -0.3758, -0.3558, -0.0021, 1.6261, 1.6193, 1.6049, 1.6007, 1.5853, 1.5845, 1.5779, 1.5771, 1.5684, 1.5675, 1.5561, 1.541, 1.541, 1.5405, 1.5202, 1.5202, 1.5201, 1.5199, 1.5194, 1.4899, 1.4897, 1.4896, 1.4896, 1.4893, 1.4891, 1.489, 1.4887, 1.4685, 1.4458, 1.445, 1.3588, 1.3896, 1.0883, 0.9446, 1.1371, 0.832, 1.2462, 1.0086, 0.1425, 1.2441, 0.6836, 0.2883, 0.3841, 0.1943, 0.6784, 0.6786, 0.3836, 0.8861, 0.1372, 0.4449, 0.3868, -0.2496, 0.3489, -0.0697, 0.482, -0.0458, 0.1433, 0.0389, 0.5498, -0.1436, -0.1654, -0.1287, 0.0153, 0.0222, 0.0456, 0.0049, 0.0533, 0.0071, -0.1305, -0.2463, -0.4516, -0.3964, -0.5347, 1.8887, 1.8758, 1.8574, 1.8565, 1.8475, 1.8373, 1.8109, 1.8105, 1.8087, 1.8076, 1.8051, 1.8044, 1.7895, 1.7829, 1.7692, 1.7284, 1.7236, 1.7228, 1.7228, 1.7223, 1.7219, 1.7218, 1.7215, 1.7215, 1.7213, 1.7209, 1.7208, 1.7208, 1.7206, 1.7204, 1.6665, 1.6642, 1.6604, 1.6593, 1.6753, 1.6568, 1.4917, 1.4635, 1.4716, 1.5156, 0.9262, 1.5139, 1.0325, 1.3136, 0.0916, 0.9553, 0.8432, 0.6162, 0.4985, 0.2933, 0.5278, 0.9387, 0.6142, -0.0411, 0.4119, 0.4016, 1.1845, 0.9219, 0.9722, 0.4217, 0.6737, 0.2108, -0.0496, 0.0399, 0.4103, 0.243, -0.092, 0.3914, -0.1847, 0.3152, 0.0428, 0.3051, -0.2991, -0.2316, -0.2602, -0.4542, -0.3112, -0.2349, 0.0289, -0.4575, -0.5062, 2.6756, 2.6744, 2.6567, 2.5659, 2.5659, 2.5658, 2.5658, 2.5649, 2.5646, 2.5633, 2.5625, 2.5587, 2.5582, 2.5569, 2.5213, 2.5113, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.3186, 2.2639, 2.1225, 2.2368, 2.2331, 2.2695, 2.2303, 2.2237, 2.2217, 2.2203, 2.2189, 2.2184, 2.1066, 2.215, 1.9918, 1.9269, 1.6773, 1.6044, 2.0937, 1.6858, 1.8877, -0.1454, 0.8041, 1.3966, 0.912, 1.2208, 0.3819, 0.7329, 0.1521, 0.7112, 0.6384, 1.2845, 1.1935, 0.7799, 0.6535, 0.0368, 0.8686, 1.5079, 0.0492, 0.5065, -0.0302, 0.3021, 0.4041, 0.0748, -0.0313, -0.3013, -0.031, -0.4526, -0.3092, -0.0569, 0.1801, -0.0138, -1.083, -0.3102, -0.1145, -0.3368, 0.0388]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 5, 5, 2, 2, 3, 4, 5, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 4, 4, 4, 1, 2, 1, 2, 3, 4, 5, 4, 5, 4, 2, 1, 2, 3, 4, 5, 2, 3, 1, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 4, 5, 5, 4, 1, 2, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 4, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 3, 1, 4, 2, 1, 3, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 5, 1, 4, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 5, 1, 3, 4, 5, 2, 4, 2, 4, 1, 2, 3, 4, 5, 4, 5, 2, 4, 4, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 3, 1, 2, 3, 4, 5, 4, 1, 3, 4, 5, 3, 5, 4, 2, 1, 2, 3, 4, 5, 2, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 5, 1, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 5, 2, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 4, 1, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 2, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 4, 1, 1, 2, 3, 4, 5, 3, 2, 3, 1, 3, 1, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 1, 1, 4, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 3, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 5, 1, 3, 4, 4, 5, 2, 1, 3, 3, 4, 1, 2, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 3, 5, 3, 1, 2, 3, 4, 5, 1, 2, 2, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 4, 1, 2, 3, 4, 5, 1, 4, 4, 1, 3, 2, 5, 1, 2, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 3, 4, 4, 5, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 2, 4, 1, 2, 2, 1, 1, 2, 3, 4, 5, 3, 3, 4, 5, 1, 1, 2, 3, 1, 2, 3, 4, 5, 2, 4, 3, 1, 2, 3, 4, 5, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 4, 2, 1, 2, 3, 4], \"Freq\": [0.15984629684647028, 0.31969259369294056, 0.07992314842323514, 0.07992314842323514, 0.31969259369294056, 0.8099401704987124, 0.3672251287110439, 0.22256068406729934, 0.07789623942355477, 0.30045692349085407, 0.0333841026100949, 0.8755046867398582, 0.27171903930345853, 0.1649722738628141, 0.19408502807389894, 0.24260628509237367, 0.1261552682480343, 0.32007720680448654, 0.16003860340224327, 0.48011581020672983, 0.47487292776655277, 0.8723090522458191, 0.13161333451217314, 0.13161333451217314, 0.3948400035365194, 0.3948400035365194, 0.9118843916335068, 0.8436023579421762, 0.06489248907247509, 0.06489248907247509, 0.6410289637069425, 0.1190482361170036, 0.10989067949261871, 0.07326045299507915, 0.05494533974630936, 0.8276582281848299, 0.8095367054407157, 0.9126925269950299, 0.7234448253228718, 0.8487007802272303, 0.09430008669191448, 0.5197925325708529, 0.18811539273992772, 0.19306579781203106, 0.06930567100944705, 0.024752025360516804, 0.811127400423705, 0.6800703955615102, 0.8098071795817937, 0.8723319594495988, 0.3812976511675563, 0.3304579643452155, 0.16099234160407935, 0.08473281137056808, 0.05083968682234084, 0.8723012983083457, 0.9320054444219543, 0.8793075531516631, 0.05172397371480371, 0.05172397371480371, 0.47416179560026717, 0.7952698324197555, 0.10844588623905757, 0.036148628746352524, 0.07229725749270505, 0.3009584925210942, 0.6019169850421884, 0.08598814072031263, 0.04299407036015632, 0.7674634685637048, 0.17054743745860107, 0.04263685936465027, 0.5628282559232163, 0.17268594215825953, 0.14710283961629514, 0.07674930762589312, 0.03837465381294656, 0.8274945272784942, 0.31966830949896113, 0.15983415474948057, 0.4262244126652815, 0.10655610316632037, 0.6800802801122318, 0.8123757553874169, 0.8859654546752757, 0.7740088499915284, 0.8653730271855502, 0.23581861769989287, 0.7074558530996786, 0.39303666400309234, 0.22030080530109636, 0.230314478269328, 0.08261280198791113, 0.07510254726173739, 0.13806851676866227, 0.06903425838433114, 0.6903425838433114, 0.06903425838433114, 0.35766823580384527, 0.09754588249195781, 0.17883411790192263, 0.3414105887218523, 0.032515294163985936, 0.9122193622063894, 0.3339276422783914, 0.21607082735660618, 0.30446343854794505, 0.09821401243482099, 0.0392856049739284, 0.2048765115080976, 0.7170677902783416, 0.32649910844091373, 0.14964542470208544, 0.38091562651439936, 0.10883303614697123, 0.04081238855511422, 0.5386707171390701, 0.1977931539495023, 0.12625094932946956, 0.08837566453062869, 0.05050037973178782, 0.6121907933080372, 0.154333813439001, 0.20063395747070126, 0.025722302239833496, 0.005144460447966699, 0.27239134755916694, 0.16343480853550016, 0.21791307804733354, 0.16343480853550016, 0.16343480853550016, 0.41965597611614525, 0.12081005373040546, 0.16531902089423905, 0.24162010746081092, 0.05086739104438125, 0.13107898274709412, 0.13107898274709412, 0.13107898274709412, 0.45877643961482945, 0.19661847412064118, 0.5530259298162321, 0.2054096310746005, 0.11060518596324642, 0.1079717291545977, 0.021067654469189796, 0.34025139847138886, 0.13610055938855553, 0.06805027969427777, 0.06805027969427777, 0.4083016781656666, 0.4451686961762424, 0.17536948637245914, 0.12140964441170247, 0.2225843480881212, 0.03372490122547291, 0.7305399633850012, 0.28468274738151855, 0.1811617483336936, 0.1811617483336936, 0.336443246905431, 0.47407260668068385, 0.5056402706008271, 0.18846591904212645, 0.19306264877486123, 0.08274113518922624, 0.02758037839640875, 0.8643219374510966, 0.8824148569907337, 0.08021953245370307, 0.7947489706758667, 0.0722499064250788, 0.0722499064250788, 0.0722499064250788, 0.474837249963324, 0.47475168272065027, 0.9287926223713212, 0.6518743569871909, 0.14922425039465814, 0.10995471081711654, 0.07853907915508324, 0.007853907915508324, 0.9320683401565698, 0.9393866152705019, 0.8097586496430471, 0.8722519833522289, 0.9040680972379346, 0.06457629265985247, 0.8028558110422868, 0.08028558110422868, 0.04014279055211434, 0.04014279055211434, 0.2501533161324516, 0.7504599483973549, 0.8568609350827775, 0.053553808442673594, 0.035702538961782396, 0.035702538961782396, 0.17583856473827733, 0.197818385330562, 0.5714753353994013, 0.08791928236913867, 0.2884982168322402, 0.5769964336644804, 0.39979987820479446, 0.18055478370539105, 0.2321418647640742, 0.07738062158802474, 0.1160709323820371, 0.7306381372760847, 0.4748529655640799, 0.2937491650769694, 0.22268081868738004, 0.2179429289280741, 0.21320503916876812, 0.047378897593059584, 0.8094059859955682, 0.0288312693789064, 0.144156346894532, 0.8361068119882855, 0.6800708503816156, 0.11275408145561543, 0.11275408145561543, 0.5637704072780771, 0.11275408145561543, 0.2009168183958288, 0.6027504551874864, 0.20088882635209948, 0.6026664790562984, 0.4297753326332618, 0.1378524651842538, 0.072980716862252, 0.3243587416100089, 0.03243587416100089, 0.3417217271440685, 0.3417217271440685, 0.7759925093739902, 0.12933208489566503, 0.733185436682678, 0.7286798550619343, 0.14573597101238686, 0.4772628317562825, 0.21835554394078283, 0.165326340412307, 0.1029390421435119, 0.03743237896127705, 0.02308285515103136, 0.4385742478695958, 0.5309056684737212, 0.02308285515103136, 0.6800754412057147, 0.9495830736288856, 0.12737298302336794, 0.7217802371324182, 0.12737298302336794, 0.6128918163396012, 0.19877572421824904, 0.12423482763640566, 0.041411609212135214, 0.02484696552728113, 0.8339683430828969, 0.9320160195481041, 0.7758048465757145, 0.4232585172456873, 0.16780071393763935, 0.252953315040322, 0.0951705541735865, 0.06010771842542305, 0.8097575856154912, 0.23264571652548632, 0.11632285826274316, 0.5816142913137158, 0.6800713084002638, 0.3365508208061554, 0.3365508208061554, 0.8096754192065564, 0.8732075617002326, 0.5139140006849083, 0.177683032151697, 0.12027774484114875, 0.1749494470416709, 0.010934340440104431, 0.6674522463479872, 0.1668630615869968, 0.8340211668525016, 0.44480048414289736, 0.19571221302287484, 0.09785610651143742, 0.19571221302287484, 0.06227206778000563, 0.28292660832400784, 0.14146330416200392, 0.3738673038567246, 0.12125426071028907, 0.07073165208100196, 0.4528608865707149, 0.4528608865707149, 0.4470559739306679, 0.08941119478613359, 0.08941119478613359, 0.35764477914453435, 0.8346429124473944, 0.16169940486183945, 0.8084970243091972, 0.4245171726757071, 0.16999265339092867, 0.21922549836207195, 0.1421250052940551, 0.04412377615338313, 0.3848504453974869, 0.26939531177824083, 0.1847282137907937, 0.11545513361924607, 0.04618205344769843, 0.7292948527133193, 0.9020287407436612, 0.04295374955922196, 0.04295374955922196, 0.33498437342125426, 0.6699687468425085, 0.540709827850617, 0.17625347979661, 0.1284559259534615, 0.11949388460787118, 0.03883551249755813, 0.6972477633299832, 0.19921364666570945, 0.03320227444428491, 0.049803411666427364, 0.016601137222142456, 0.5582608733954884, 0.16629047292631569, 0.13659574561804502, 0.13659574561804502, 0.011877890923308264, 0.5539422226054737, 0.17288642616349179, 0.16582983734049211, 0.07762247705299631, 0.028226355291998656, 0.8729377708175755, 0.49219869364527336, 0.24609934682263668, 0.147659608093582, 0.04921986936452734, 0.06328268918296372, 0.05923638722777562, 0.4146547105944293, 0.23694554891110248, 0.05923638722777562, 0.23694554891110248, 0.8279668373026505, 0.1655933674605301, 0.33681941237114454, 0.33681941237114454, 0.21587705931488851, 0.21587705931488851, 0.43175411862977703, 0.4265026908197394, 0.29181763056087434, 0.06734253012943253, 0.04489502008628836, 0.17958008034515344, 0.9286962178189436, 0.5163316386845045, 0.13725271408069106, 0.13725271408069106, 0.13725271408069106, 0.07189427880417151, 0.6800721719185795, 0.8257040199577103, 0.8723127333342022, 0.3366919671089123, 0.3366919671089123, 0.5039268684109116, 0.20780489419006662, 0.14546342593304665, 0.09870732474028164, 0.04675610119276499, 0.326991219575276, 0.11890589802737309, 0.11890589802737309, 0.35671769408211923, 0.05945294901368654, 0.8719684295920097, 0.8098672872076096, 0.24177822661690915, 0.7253346798507274, 0.9122840481230358, 0.40687732931721354, 0.17131677023882674, 0.2783897516380935, 0.0999347826393156, 0.042829192559706686, 0.6715506143993465, 0.13990637799986386, 0.13990637799986386, 0.02798127559997277, 0.013990637799986385, 0.47143942667271166, 0.1728611231133276, 0.18857577066908468, 0.0864305615566638, 0.07857323777878528, 0.9379834423154, 0.8724815777862611, 0.9769506867353606, 0.5381904609075474, 0.17228193224519223, 0.14788803033436856, 0.12501874729297136, 0.01677080756369128, 0.7501275277973136, 0.10346586590307774, 0.025866466475769435, 0.10346586590307774, 0.025866466475769435, 0.7267580138759914, 0.5194339855904172, 0.20122217459808955, 0.19654258914232003, 0.07019378183654286, 0.018718341823078098, 0.8254275848263557, 0.07283184571997256, 0.09710912762663007, 0.8067698672229208, 0.09491410202622597, 0.04745705101311298, 0.04745705101311298, 0.8095750131043157, 0.8671478018577607, 0.932025856846413, 0.5984116791291109, 0.14960291978227772, 0.12240238891277268, 0.11560225619539642, 0.01360026543475252, 0.8305219950309435, 0.4770961614298872, 0.1866898022986515, 0.1991357891185616, 0.10371655683258417, 0.0373379604597303, 0.8097510765377808, 0.5281861238171341, 0.16960104893210728, 0.16960104893210728, 0.10660637361446744, 0.024228721276015327, 0.27472090546419153, 0.4578681757736526, 0.12820308921662274, 0.10988836218567662, 0.036629454061892205, 0.7758087272799967, 0.47452496026110225, 0.9291640164069518, 0.15974659735369723, 0.6389863894147889, 0.15974659735369723, 0.26874844359791167, 0.18812391051853816, 0.45687235411644983, 0.053749688719582335, 0.026874844359791168, 0.6767767109660185, 0.10539965170782255, 0.11649435188759334, 0.06656820107862477, 0.03883145062919778, 0.8722242950963218, 0.20085117195602903, 0.6025535158680871, 0.8654704336637798, 0.5797857612348768, 0.15429782355444302, 0.13091936544013347, 0.08416244921151438, 0.05610829947434292, 0.9032979035566157, 0.38525179712708624, 0.5926950725032096, 0.8345704310463589, 0.7757312527507679, 0.834322707477166, 0.4619579844373055, 0.21739199267637907, 0.09510899679591585, 0.19701149336296853, 0.03396749885568423, 0.34191779308302594, 0.34191779308302594, 0.42605476296239897, 0.17717128756852232, 0.2784120233219637, 0.0928040077739879, 0.025310183938360334, 0.8721610251454641, 0.949493976865087, 0.8655080344413376, 0.6800699622502637, 0.5190153534185648, 0.13455953607147975, 0.16018992389461875, 0.13455953607147975, 0.048056977168385626, 0.8864070308425779, 0.33730554647798233, 0.3017996994803, 0.257417390733197, 0.08876461749420587, 0.017752923498841177, 0.2825277465719624, 0.4036110665313748, 0.22198608659225616, 0.08072221330627496, 0.5064851488830906, 0.1470440754821876, 0.10619849895935769, 0.19605876730958344, 0.040845576522829885, 0.9289924988146612, 0.9122776682738796, 0.3320667757918694, 0.6087890889517605, 0.05534446263197823, 0.9138424046215631, 0.2884336342884436, 0.5768672685768872, 0.8724841076312476, 0.2722415188495994, 0.21036844638378135, 0.3712384347949083, 0.09899691594530888, 0.037123843479490826, 0.4722299754669656, 0.1791217148322973, 0.1791217148322973, 0.04885137677244472, 0.11398654580237101, 0.4046637239118891, 0.18676787257471805, 0.22412144708966167, 0.13073751080230264, 0.05603036177241542, 0.8728404050854105, 0.9320330910257024, 0.9320457459543249, 0.8668378641891046, 0.8345541674926323, 0.4084224548523475, 0.2506228700230314, 0.19028773464711646, 0.13459376353088726, 0.013923492779057302, 0.2241989050259224, 0.10722556327326724, 0.48738892396939654, 0.1559644556702069, 0.01949555695877586, 0.3840450312335331, 0.2922081759385578, 0.10853446534860718, 0.17532490556313468, 0.04174402513407969, 0.8748178439835745, 0.07952889490759768, 0.6800726058922119, 0.47483711720603855, 0.8025779444177491, 0.06978938647110862, 0.10468407970666294, 0.27517753934701533, 0.5503550786940307, 0.8722686215070656, 0.8640037627341677, 0.7757894240991984, 0.8714531850919677, 0.60530963682111, 0.03188765135004438, 0.9247418891512871, 0.6456413234017851, 0.1191953212434065, 0.10926237780645595, 0.08939649093255488, 0.039731773747802165, 0.3420503889637106, 0.3420503889637106, 0.4656914741256275, 0.07055931426145871, 0.1270067656706257, 0.2540135313412514, 0.08467117711375045, 0.875508662148086, 0.4746997901549099, 0.973104194478036, 0.44715521261526375, 0.21620691598979785, 0.19655174180890714, 0.08844828381400821, 0.049137935452226784, 0.8642321491811764, 0.8722634226332471, 0.9624358296382707, 0.8455754157367625, 0.13008852549796346, 0.6800760492880974, 0.4421983110450957, 0.27506824072883906, 0.1497206879916466, 0.08356503515812833, 0.05222814697383021, 0.3122941656531599, 0.2136749554468989, 0.2958576306187831, 0.07396440765469578, 0.10683747772344945, 0.45137695671529326, 0.06944260872542973, 0.2083278261762892, 0.06944260872542973, 0.2083278261762892, 0.33694621748194337, 0.33694621748194337, 0.4745846034633905, 0.7419263957272415, 0.06182719964393679, 0.09274079946590519, 0.06182719964393679, 0.6800706141190541, 0.2329220195107772, 0.28914457594441306, 0.20079484440584242, 0.17669946307714132, 0.09638152531480436, 0.47427758746297743, 0.9033259954395295, 0.34450396963195007, 0.30397409085172067, 0.2229143332912618, 0.10132469695057354, 0.010132469695057355, 0.7291534682481335, 0.23803766995257358, 0.7141130098577207, 0.41751789246596205, 0.18490078094921175, 0.17297169830732712, 0.1968298635910964, 0.03578724792565389, 0.18999896280911913, 0.25333195041215884, 0.3483314318167184, 0.18999896280911913, 0.9093110111406433, 0.3923770789046966, 0.2092677754158382, 0.16567032220420522, 0.14823134091955203, 0.08719490642326591, 0.2922451236324736, 0.6819052884757718, 0.729546738949104, 0.14272036260581575, 0.7136018130290788, 0.33634996850962035, 0.33634996850962035, 0.8638365254747705, 0.05758910169831803, 0.05758910169831803, 0.33362633574497086, 0.3606771197242928, 0.13525391989660981, 0.07213542394485856, 0.10820313591728785, 0.9320620057867525, 0.5750666660855117, 0.20854065912991085, 0.10111062260844163, 0.08847179478238643, 0.025277655652110407, 0.8343613470044963, 0.7758007605685722, 0.9124928374846522, 0.8099191197871356, 0.6800720696612108, 0.6800768789376526, 0.9093890853254369, 0.1472348509311165, 0.44170455279334947, 0.11042613819833737, 0.03680871273277912, 0.25766098912945384, 0.4405575337822057, 0.1639283846631463, 0.2049104808289329, 0.09220971637301979, 0.10245524041446645, 0.6859046687859304, 0.2182423946137051, 0.031177484944815016, 0.04676622741722252, 0.1393648330707093, 0.1742060413383866, 0.3135708744090959, 0.1742060413383866, 0.24388845787374125, 0.21534473004819055, 0.5742526134618414, 0.14356315336546036, 0.07178157668273018, 0.3536656599168596, 0.15256165721903747, 0.27045021052465734, 0.11095393252293635, 0.11095393252293635, 0.2546639450040619, 0.5942158716761444, 0.1188431743352289, 0.033955192667208256, 0.5072311077250112, 0.15819584052809757, 0.1782842012300782, 0.12304120929963144, 0.03264358614071854, 0.8347052540188401, 0.07365046358989766, 0.024550154529965885, 0.04910030905993177, 0.30551580154437585, 0.6110316030887517, 0.10183860051479195, 0.8344555270287634, 0.5695279229555995, 0.13921793672247987, 0.2088269050837198, 0.05695279229555995, 0.03164044016419997, 0.6690534812614052, 0.13886015648821615, 0.1136128553085405, 0.05049460235935133, 0.0378709517695135, 0.8726053255782635, 0.8305175891152183, 0.9123418139790918, 0.22086148730868085, 0.22086148730868085, 0.22086148730868085, 0.14724099153912057, 0.29448198307824114, 0.42093904446066727, 0.2955529461106813, 0.08956149882141856, 0.1612106978785534, 0.035824599528567425, 0.6282289703772246, 0.20103327052071188, 0.04188193135848164, 0.10051663526035594, 0.025129158815088985, 0.5144804048915079, 0.15210725014183715, 0.16105473544429816, 0.16105473544429816, 0.013421227953691512, 0.47045245808430053, 0.31363497205620033, 0.11201249002007155, 0.08960999201605724, 0.011201249002007155, 0.5342752841858832, 0.12970845049599478, 0.18220948998246886, 0.0988254860921865, 0.052501039486474076, 0.8536713884391878, 0.10670892355489847, 0.8722539396590867, 0.8096487343025742, 0.8655386887761903, 0.8726799920997051, 0.9288633725406228, 0.9085570611154166, 0.2755373847757383, 0.1549897789363528, 0.1549897789363528, 0.3616428175181565, 0.03444217309696729, 0.9112330176515492, 0.8304919189943558, 0.8097016077988547, 0.6800730404180755, 0.8644965340046833, 0.792797820457654, 0.04172620107671863, 0.1251786032301559, 0.7969836695706657, 0.07245306087006051, 0.07245306087006051, 0.036226530435030255, 0.036226530435030255, 0.8270942425216516, 0.8096918920682933, 0.9320543914343496, 0.35344098212616853, 0.1413763928504674, 0.11781366070872284, 0.32987824998442394, 0.0706881964252337, 0.927674571508218, 0.16217014209782407, 0.6486805683912963, 0.2706422851693151, 0.16915142823082194, 0.43979371340013707, 0.07611814270386988, 0.05074542846924659, 0.39766521506119157, 0.30257135928568923, 0.18154281557141355, 0.1210285437142757, 0.38293836292013195, 0.21718892225320915, 0.18289593452901823, 0.19432693043708188, 0.02286199181612728, 0.6515301836163736, 0.07446059241329984, 0.16753633292992465, 0.0930757405166248, 0.00930757405166248, 0.46089032008392095, 0.25965651835713854, 0.15579391101428314, 0.07789695550714157, 0.038948477753570784, 0.3364434578068604, 0.3364434578068604, 0.8720623186213194, 0.07927839260193813, 0.39221907209734, 0.2150878782469284, 0.3289579314364787, 0.050608912528689036, 0.025304456264344518, 0.6800707982587331, 0.39234020415128423, 0.28276771470362827, 0.2191449788953119, 0.09543410371247454, 0.014138385735181414, 0.5022438683364411, 0.2041641741205045, 0.1674146227788137, 0.08983223661302198, 0.03674955134169081, 0.8684266681592868, 0.40948317791186806, 0.09535909622605147, 0.28046793007662196, 0.16828075804597317, 0.05048422741379195, 0.20111496189835126, 0.6033448856950537, 0.8682975582479645, 0.43305350530873926, 0.33942031497171454, 0.0936331903370247, 0.12874563671340897], \"Term\": [\"1060\", \"1060\", \"1060\", \"1060\", \"1060\", \"130h\", \"2\", \"2\", \"2\", \"2\", \"2\", \"20201215\", \"2077\", \"2077\", \"2077\", \"2077\", \"2077\", \"23\", \"23\", \"23\", \"345\", \"40fps\", \"accept\", \"accept\", \"accept\", \"accept\", \"acclaimed\", \"across\", \"across\", \"across\", \"actually\", \"actually\", \"actually\", \"actually\", \"actually\", \"adding\", \"address\", \"adult\", \"advance\", \"ahead\", \"ahead\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ammo\", \"amounted\", \"analysis\", \"apparent\", \"around\", \"around\", \"around\", \"around\", \"around\", \"artistic\", \"assim\", \"attribute\", \"attribute\", \"attribute\", \"autosave\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"b\", \"b\", \"b\", \"b\", \"background\", \"background\", \"background\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bir\", \"bland\", \"bland\", \"bland\", \"bland\", \"bleed\", \"blue\", \"bois\", \"bounty\", \"boxing\", \"brutal\", \"brutal\", \"bug\", \"bug\", \"bug\", \"bug\", \"bug\", \"bugged\", \"bugged\", \"bugged\", \"bugged\", \"buggy\", \"buggy\", \"buggy\", \"buggy\", \"buggy\", \"butterfly\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"c\", \"c\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cannot\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"car\", \"car\", \"car\", \"car\", \"car\", \"cd\", \"cd\", \"cd\", \"cd\", \"cd\", \"cdpr\", \"cdpr\", \"cdpr\", \"cdpr\", \"cdpr\", \"changed\", \"changed\", \"changed\", \"changed\", \"changed\", \"character\", \"character\", \"character\", \"character\", \"character\", \"check\", \"check\", \"check\", \"check\", \"check\", \"choice\", \"choice\", \"choice\", \"choice\", \"choice\", \"choicedriven\", \"choose\", \"choose\", \"choose\", \"choose\", \"circling\", \"city\", \"city\", \"city\", \"city\", \"city\", \"claim\", \"click\", \"click\", \"close\", \"close\", \"close\", \"close\", \"cmon\", \"coding\", \"com\", \"combat\", \"combat\", \"combat\", \"combat\", \"combat\", \"como\", \"comparing\", \"completly\", \"conceiving\", \"conversation\", \"conversation\", \"cover\", \"cover\", \"cover\", \"cover\", \"cp\", \"cp\", \"crafting\", \"crafting\", \"crafting\", \"crafting\", \"crash\", \"crash\", \"crash\", \"crash\", \"cred\", \"cred\", \"current\", \"current\", \"current\", \"current\", \"current\", \"customer\", \"cyberbug\", \"cyberpunk\", \"cyberpunk\", \"cyberpunk\", \"cyberpunk\", \"cyberpunk\", \"cyberspace\", \"de\", \"de\", \"de\", \"dec\", \"delivered\", \"delivered\", \"delivered\", \"delivered\", \"demand\", \"demand\", \"destiny\", \"destiny\", \"dialogue\", \"dialogue\", \"dialogue\", \"dialogue\", \"dialogue\", \"dick\", \"dick\", \"directly\", \"directly\", \"dismantle\", \"dmg\", \"dmg\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"e\", \"e\", \"e\", \"e\", \"eathat\", \"eles\", \"em\", \"em\", \"em\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"enemy\", \"engine\", \"est\", \"eu\", \"even\", \"even\", \"even\", \"even\", \"even\", \"everybody\", \"exciting\", \"exciting\", \"exciting\", \"excluded\", \"explained\", \"explained\", \"exploitation\", \"facility\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"fetch\", \"fetch\", \"firearm\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"forbid\", \"forbid\", \"frustrating\", \"frustrating\", \"frustrating\", \"frustrating\", \"funniest\", \"g\", \"g\", \"game\", \"game\", \"game\", \"game\", \"game\", \"gameplay\", \"gameplay\", \"gameplay\", \"gameplay\", \"gameplay\", \"gay\", \"gear\", \"gear\", \"gear\", \"genuinely\", \"genuinely\", \"get\", \"get\", \"get\", \"get\", \"get\", \"getting\", \"getting\", \"getting\", \"getting\", \"getting\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"granted\", \"great\", \"great\", \"great\", \"great\", \"great\", \"gtx\", \"gtx\", \"gtx\", \"gtx\", \"gtx\", \"happy\", \"happy\", \"held\", \"held\", \"hence\", \"hence\", \"hence\", \"high\", \"high\", \"high\", \"high\", \"high\", \"hist\", \"hour\", \"hour\", \"hour\", \"hour\", \"hour\", \"howd\", \"hp\", \"i9\", \"illegal\", \"illegal\", \"im\", \"im\", \"im\", \"im\", \"im\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"increasingly\", \"intersting\", \"interview\", \"interview\", \"ironically\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"item\", \"item\", \"item\", \"item\", \"item\", \"ive\", \"ive\", \"ive\", \"ive\", \"ive\", \"jogo\", \"k\", \"l\", \"like\", \"like\", \"like\", \"like\", \"like\", \"limited\", \"limited\", \"limited\", \"limited\", \"limited\", \"lmao\", \"look\", \"look\", \"look\", \"look\", \"look\", \"loot\", \"loot\", \"loot\", \"lore\", \"lore\", \"lore\", \"lore\", \"lovingly\", \"lvl\", \"ma\", \"main\", \"main\", \"main\", \"main\", \"main\", \"mais\", \"make\", \"make\", \"make\", \"make\", \"make\", \"mandatory\", \"many\", \"many\", \"many\", \"many\", \"many\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mesmo\", \"messing\", \"mi\", \"min\", \"min\", \"min\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mission\", \"mission\", \"mission\", \"mission\", \"mission\", \"mmo\", \"modded\", \"modded\", \"monster\", \"much\", \"much\", \"much\", \"much\", \"much\", \"muito\", \"n\", \"n\", \"neck\", \"nem\", \"netrunner\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"noticeable\", \"noticeable\", \"npc\", \"npc\", \"npc\", \"npc\", \"npc\", \"nvme\", \"o\", \"occasionally\", \"ofc\", \"one\", \"one\", \"one\", \"one\", \"one\", \"op\", \"open\", \"open\", \"open\", \"open\", \"open\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"option\", \"option\", \"option\", \"option\", \"option\", \"outright\", \"overrated\", \"p\", \"p\", \"p\", \"pacing\", \"paid\", \"paid\", \"pasted\", \"patch\", \"patch\", \"patch\", \"patch\", \"patch\", \"pc\", \"pc\", \"pc\", \"pc\", \"pc\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfectly\", \"personagem\", \"personagens\", \"perspective\", \"picture\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"player\", \"player\", \"player\", \"playing\", \"playing\", \"playing\", \"playing\", \"playing\", \"plenty\", \"plenty\", \"pls\", \"pogchamp\", \"pointless\", \"pointless\", \"pointless\", \"policy\", \"policy\", \"poof\", \"popping\", \"por\", \"pra\", \"preanimated\", \"preordering\", \"preordering\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"pretty\", \"profile\", \"profile\", \"promised\", \"promised\", \"promised\", \"promised\", \"promised\", \"proof\", \"punk\", \"que\", \"quest\", \"quest\", \"quest\", \"quest\", \"quest\", \"quickhack\", \"quote\", \"r\", \"ran\", \"ran\", \"realcrowbcats\", \"really\", \"really\", \"really\", \"really\", \"really\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"refund\", \"refund\", \"refund\", \"refund\", \"refund\", \"remapping\", \"remapping\", \"renamed\", \"rest\", \"rest\", \"rest\", \"rest\", \"revew\", \"review\", \"review\", \"review\", \"review\", \"review\", \"reviewing\", \"ria\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rofl\", \"router\", \"router\", \"rpg\", \"rpg\", \"rpg\", \"rpg\", \"rpg\", \"rtx\", \"rtx\", \"rtx\", \"rtx\", \"sake\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scam\", \"scam\", \"schematic\", \"se\", \"se\", \"self\", \"self\", \"seriously\", \"seriously\", \"seriously\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"seu\", \"side\", \"side\", \"side\", \"side\", \"side\", \"sign\", \"simplesmente\", \"sin\", \"smoothed\", \"smoothing\", \"softlocking\", \"spam\", \"spec\", \"spec\", \"spec\", \"spec\", \"spec\", \"state\", \"state\", \"state\", \"state\", \"state\", \"stealth\", \"stealth\", \"stealth\", \"stealth\", \"steam\", \"steam\", \"steam\", \"steam\", \"steam\", \"step\", \"step\", \"step\", \"step\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stop\", \"stop\", \"stop\", \"stop\", \"story\", \"story\", \"story\", \"story\", \"story\", \"stuck\", \"stuck\", \"stuck\", \"stuck\", \"substance\", \"substance\", \"substance\", \"superb\", \"system\", \"system\", \"system\", \"system\", \"system\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tek\", \"tem\", \"terribly\", \"text\", \"text\", \"text\", \"text\", \"text\", \"thats\", \"thats\", \"thats\", \"thats\", \"thats\", \"there\", \"there\", \"there\", \"there\", \"there\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"time\", \"towards\", \"towards\", \"trade\", \"trans\", \"treated\", \"turnoff\", \"tw3\", \"twice\", \"u\", \"u\", \"u\", \"u\", \"u\", \"um\", \"uma\", \"unengaging\", \"uneven\", \"unno\", \"upgrade\", \"upgrade\", \"upgrade\", \"useless\", \"useless\", \"useless\", \"useless\", \"useless\", \"v104\", \"valve\", \"vel\", \"video\", \"video\", \"video\", \"video\", \"video\", \"voc\", \"w\", \"w\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"want\", \"want\", \"want\", \"want\", \"way\", \"way\", \"way\", \"way\", \"way\", \"weapon\", \"weapon\", \"weapon\", \"weapon\", \"weapon\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wholesome\", \"wholesome\", \"wise\", \"wise\", \"without\", \"without\", \"without\", \"without\", \"without\", \"witnessed\", \"world\", \"world\", \"world\", \"world\", \"world\", \"would\", \"would\", \"would\", \"would\", \"would\", \"yak\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yellow\", \"yellow\", \"yle\", \"youre\", \"youre\", \"youre\", \"youre\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 5, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el421215798939424723023762752\", ldavis_el421215798939424723023762752_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el421215798939424723023762752\", ldavis_el421215798939424723023762752_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el421215798939424723023762752\", ldavis_el421215798939424723023762752_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.045734 -0.001178       1        1  43.820427\n",
       "0      0.022307  0.016664       2        1  19.096114\n",
       "2      0.008787  0.052409       3        1  18.999892\n",
       "4      0.013749 -0.066408       4        1  12.983938\n",
       "1     -0.090577 -0.001487       5        1   5.099628, topic_info=       Term         Freq        Total Category  logprob  loglift\n",
       "1      game  2153.000000  2153.000000  Default  30.0000  30.0000\n",
       "10      bug   399.000000   399.000000  Default  29.0000  29.0000\n",
       "25     even   399.000000   399.000000  Default  28.0000  28.0000\n",
       "66    still   144.000000   144.000000  Default  27.0000  27.0000\n",
       "443  really   287.000000   287.000000  Default  26.0000  26.0000\n",
       "..      ...          ...          ...      ...      ...      ...\n",
       "134    like    11.324462   655.901629   Topic5  -5.7033  -1.0830\n",
       "93     make     9.014082   241.041554   Topic5  -5.9315  -0.3102\n",
       "204      im     8.754229   192.488248   Topic5  -5.9607  -0.1145\n",
       "160   would     8.917607   244.900949   Topic5  -5.9422  -0.3368\n",
       "420  people     8.515533   160.627198   Topic5  -5.9884   0.0388\n",
       "\n",
       "[446 rows x 6 columns], token_table=      Topic      Freq   Term\n",
       "term                        \n",
       "3146      1  0.159846   1060\n",
       "3146      2  0.319693   1060\n",
       "3146      3  0.079923   1060\n",
       "3146      4  0.079923   1060\n",
       "3146      5  0.319693   1060\n",
       "...     ...       ...    ...\n",
       "6887      2  0.868298    yle\n",
       "499       1  0.433054  youre\n",
       "499       2  0.339420  youre\n",
       "499       3  0.093633  youre\n",
       "499       4  0.128746  youre\n",
       "\n",
       "[871 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 5, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(X_split_neg)\n",
    "corpus = [id2word.doc2bow(review) for review in X_split_neg]\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=5, passes=10, iterations=100, random_state=212)\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Unlabeled Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the full models are made, I will need to run them against unlabeled data I collect from reddit and/or twitter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
